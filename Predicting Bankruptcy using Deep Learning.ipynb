{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qp8LgVkr55XX"
   },
   "source": [
    "# Predicting Bankruptcy using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "arYUUR6Z6c32"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h5J4BedruTYV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "4WZIUc_H7aZ_",
    "outputId": "6d500040-5437-4582-eeb0-91e904f39051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Rur5wZtf1BQ-",
    "outputId": "c1d451bd-6f37-4dd2-fd77-4672344dca05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nikhil\\\\Desktop\\\\SPJ-Financial Analytics'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvRaWCeH7dZb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TUS44yn76muE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Balanced_dataset_asof0817/Balanced_dataset_asof0817')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "taU7QNj0659g",
    "outputId": "188ea59b-089a-4dbc-a287-271278fede91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.007865</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.175039</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.038711</td>\n",
       "      <td>0.032867</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.024988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016935</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.013940</td>\n",
       "      <td>-0.020445</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.044682</td>\n",
       "      <td>-0.379891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.012523</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.150387</td>\n",
       "      <td>0.046052</td>\n",
       "      <td>0.038885</td>\n",
       "      <td>0.033454</td>\n",
       "      <td>0.034460</td>\n",
       "      <td>0.031195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521458</td>\n",
       "      <td>-0.032052</td>\n",
       "      <td>-0.013547</td>\n",
       "      <td>-0.019600</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>0.037082</td>\n",
       "      <td>0.113446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.012561</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.181403</td>\n",
       "      <td>-0.148071</td>\n",
       "      <td>0.038827</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016130</td>\n",
       "      <td>-0.005928</td>\n",
       "      <td>-0.009726</td>\n",
       "      <td>-0.030213</td>\n",
       "      <td>-0.024310</td>\n",
       "      <td>-0.079108</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.162260</td>\n",
       "      <td>1.654544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.007925</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.182106</td>\n",
       "      <td>-0.088925</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.032366</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012172</td>\n",
       "      <td>-0.031993</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.054409</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>0.125792</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>0.265480</td>\n",
       "      <td>-0.443563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.010104</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.158995</td>\n",
       "      <td>0.416657</td>\n",
       "      <td>0.038868</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.034165</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015725</td>\n",
       "      <td>-0.019109</td>\n",
       "      <td>-0.016223</td>\n",
       "      <td>-0.045763</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.077117</td>\n",
       "      <td>-0.290066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0  0.007208 -0.007865  0.007028 -0.175039  0.028868  0.038711   \n",
       "1           1  0.007208 -0.012523  0.007028 -0.150387  0.046052  0.038885   \n",
       "2           2  0.007208 -0.012561  0.007028 -0.181403 -0.148071  0.038827   \n",
       "3           3  0.007208 -0.007925  0.007028 -0.182106 -0.088925  0.036465   \n",
       "4           4  0.007208 -0.010104  0.007028 -0.158995  0.416657  0.038868   \n",
       "\n",
       "          6         7         8  ...        48        49        50        51  \\\n",
       "0  0.032867  0.033783  0.024988  ... -0.016935 -0.004814 -0.013940 -0.020445   \n",
       "1  0.033454  0.034460  0.031195  ...  0.521458 -0.032052 -0.013547 -0.019600   \n",
       "2  0.032841  0.034234  0.024823  ... -0.016130 -0.005928 -0.009726 -0.030213   \n",
       "3  0.030983  0.032366  0.025871  ... -0.012172 -0.031993  0.004242  0.054409   \n",
       "4  0.032841  0.034165  0.024293  ... -0.015725 -0.019109 -0.016223 -0.045763   \n",
       "\n",
       "         52        53        54        55        56  label  \n",
       "0 -0.024377 -0.082360 -0.037266 -0.044682 -0.379891      0  \n",
       "1 -0.024377  0.099773 -0.037266  0.037082  0.113446      0  \n",
       "2 -0.024310 -0.079108 -0.037266 -0.162260  1.654544      0  \n",
       "3 -0.024377  0.125792 -0.037266  0.265480 -0.443563      0  \n",
       "4 -0.024377 -0.082360 -0.037266 -0.077117 -0.290066      0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "FdZ3nkp77nxv",
    "outputId": "bb14968c-1511-4ed9-9138-7210a8844996"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.007865</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.175039</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.038711</td>\n",
       "      <td>0.032867</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.024988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016935</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.013940</td>\n",
       "      <td>-0.020445</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.044682</td>\n",
       "      <td>-0.379891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.012523</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.150387</td>\n",
       "      <td>0.046052</td>\n",
       "      <td>0.038885</td>\n",
       "      <td>0.033454</td>\n",
       "      <td>0.034460</td>\n",
       "      <td>0.031195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521458</td>\n",
       "      <td>-0.032052</td>\n",
       "      <td>-0.013547</td>\n",
       "      <td>-0.019600</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>0.037082</td>\n",
       "      <td>0.113446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.012561</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.181403</td>\n",
       "      <td>-0.148071</td>\n",
       "      <td>0.038827</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016130</td>\n",
       "      <td>-0.005928</td>\n",
       "      <td>-0.009726</td>\n",
       "      <td>-0.030213</td>\n",
       "      <td>-0.024310</td>\n",
       "      <td>-0.079108</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.162260</td>\n",
       "      <td>1.654544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.007925</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.182106</td>\n",
       "      <td>-0.088925</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.032366</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012172</td>\n",
       "      <td>-0.031993</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.054409</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>0.125792</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>0.265480</td>\n",
       "      <td>-0.443563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.010104</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.158995</td>\n",
       "      <td>0.416657</td>\n",
       "      <td>0.038868</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.034165</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015725</td>\n",
       "      <td>-0.019109</td>\n",
       "      <td>-0.016223</td>\n",
       "      <td>-0.045763</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.077117</td>\n",
       "      <td>-0.290066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39956</th>\n",
       "      <td>39956</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.182851</td>\n",
       "      <td>-0.131705</td>\n",
       "      <td>0.036661</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.023019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017033</td>\n",
       "      <td>-0.027783</td>\n",
       "      <td>-0.006135</td>\n",
       "      <td>0.191123</td>\n",
       "      <td>-0.024329</td>\n",
       "      <td>-0.048303</td>\n",
       "      <td>-0.011602</td>\n",
       "      <td>-0.019291</td>\n",
       "      <td>-0.329352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39957</th>\n",
       "      <td>39957</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.182895</td>\n",
       "      <td>-0.119716</td>\n",
       "      <td>0.036983</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.032569</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017217</td>\n",
       "      <td>-0.029197</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>0.531933</td>\n",
       "      <td>-0.024243</td>\n",
       "      <td>-0.043931</td>\n",
       "      <td>-0.021744</td>\n",
       "      <td>-0.034785</td>\n",
       "      <td>-0.205704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39958</th>\n",
       "      <td>39958</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.048103</td>\n",
       "      <td>0.176397</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017820</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>-0.026220</td>\n",
       "      <td>-0.063531</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.036509</td>\n",
       "      <td>-0.360805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39959</th>\n",
       "      <td>39959</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.008278</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.166330</td>\n",
       "      <td>-0.038964</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.030590</td>\n",
       "      <td>0.031627</td>\n",
       "      <td>0.025897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018941</td>\n",
       "      <td>-0.020796</td>\n",
       "      <td>-0.019736</td>\n",
       "      <td>-0.050688</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.060096</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>-0.216671</td>\n",
       "      <td>-0.431634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39960</th>\n",
       "      <td>39960</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>-0.141492</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012053</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.017097</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>-0.005178</td>\n",
       "      <td>-0.012737</td>\n",
       "      <td>-0.016289</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>-0.361331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39961 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0               0  0.007208 -0.007865  0.007028 -0.175039  0.028868  0.038711   \n",
       "1               1  0.007208 -0.012523  0.007028 -0.150387  0.046052  0.038885   \n",
       "2               2  0.007208 -0.012561  0.007028 -0.181403 -0.148071  0.038827   \n",
       "3               3  0.007208 -0.007925  0.007028 -0.182106 -0.088925  0.036465   \n",
       "4               4  0.007208 -0.010104  0.007028 -0.158995  0.416657  0.038868   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "39956       39956  0.007208  0.006839  0.007028 -0.182851 -0.131705  0.036661   \n",
       "39957       39957  0.007208  0.003076  0.007028 -0.182895 -0.119716  0.036983   \n",
       "39958       39958  0.007208  0.003660  0.007028 -0.048103  0.176397  0.020637   \n",
       "39959       39959  0.007208 -0.008278  0.007028 -0.166330 -0.038964  0.038833   \n",
       "39960       39960  0.007208  0.004092  0.007028  0.023787 -0.141492  0.019094   \n",
       "\n",
       "              6         7         8  ...        48        49        50  \\\n",
       "0      0.032867  0.033783  0.024988  ... -0.016935 -0.004814 -0.013940   \n",
       "1      0.033454  0.034460  0.031195  ...  0.521458 -0.032052 -0.013547   \n",
       "2      0.032841  0.034234  0.024823  ... -0.016130 -0.005928 -0.009726   \n",
       "3      0.030983  0.032366  0.025871  ... -0.012172 -0.031993  0.004242   \n",
       "4      0.032841  0.034165  0.024293  ... -0.015725 -0.019109 -0.016223   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "39956  0.032207  0.032183  0.023019  ... -0.017033 -0.027783 -0.006135   \n",
       "39957  0.032300  0.032569  0.023719  ... -0.017217 -0.029197 -0.003584   \n",
       "39958  0.015031  0.014398  0.005987  ... -0.017820  0.123967 -0.026220   \n",
       "39959  0.030590  0.031627  0.025897  ... -0.018941 -0.020796 -0.019736   \n",
       "39960  0.015899  0.016508  0.019678  ... -0.012053 -0.005083 -0.017097   \n",
       "\n",
       "             51        52        53        54        55        56  label  \n",
       "0     -0.020445 -0.024377 -0.082360 -0.037266 -0.044682 -0.379891      0  \n",
       "1     -0.019600 -0.024377  0.099773 -0.037266  0.037082  0.113446      0  \n",
       "2     -0.030213 -0.024310 -0.079108 -0.037266 -0.162260  1.654544      0  \n",
       "3      0.054409 -0.024377  0.125792 -0.037266  0.265480 -0.443563      0  \n",
       "4     -0.045763 -0.024377 -0.082360 -0.037266 -0.077117 -0.290066      0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "39956  0.191123 -0.024329 -0.048303 -0.011602 -0.019291 -0.329352      1  \n",
       "39957  0.531933 -0.024243 -0.043931 -0.021744 -0.034785 -0.205704      1  \n",
       "39958 -0.063531 -0.024377 -0.082360 -0.037266 -0.036509 -0.360805      1  \n",
       "39959 -0.050688 -0.024377 -0.060096  0.019104 -0.216671 -0.431634      1  \n",
       "39960  0.093782 -0.005178 -0.012737 -0.016289  0.147700 -0.361331      1  \n",
       "\n",
       "[39961 rows x 59 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UbrNm2vn8pbJ",
    "outputId": "a1133eb7-3b76-40b4-c400-6d8d86e1a726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39961 entries, 0 to 39960\n",
      "Data columns (total 59 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  39961 non-null  int64  \n",
      " 1   0           39961 non-null  float64\n",
      " 2   1           39961 non-null  float64\n",
      " 3   2           39961 non-null  float64\n",
      " 4   3           39961 non-null  float64\n",
      " 5   4           39961 non-null  float64\n",
      " 6   5           39961 non-null  float64\n",
      " 7   6           39961 non-null  float64\n",
      " 8   7           39961 non-null  float64\n",
      " 9   8           39961 non-null  float64\n",
      " 10  9           39961 non-null  float64\n",
      " 11  10          39961 non-null  float64\n",
      " 12  11          39961 non-null  float64\n",
      " 13  12          39961 non-null  float64\n",
      " 14  13          39961 non-null  float64\n",
      " 15  14          39961 non-null  float64\n",
      " 16  15          39961 non-null  float64\n",
      " 17  16          39961 non-null  float64\n",
      " 18  17          39961 non-null  float64\n",
      " 19  18          39961 non-null  float64\n",
      " 20  19          39961 non-null  float64\n",
      " 21  20          39961 non-null  float64\n",
      " 22  21          39961 non-null  float64\n",
      " 23  22          39961 non-null  float64\n",
      " 24  23          39961 non-null  float64\n",
      " 25  24          39961 non-null  float64\n",
      " 26  25          39961 non-null  float64\n",
      " 27  26          39961 non-null  float64\n",
      " 28  27          39961 non-null  float64\n",
      " 29  28          39961 non-null  float64\n",
      " 30  29          39961 non-null  float64\n",
      " 31  30          39961 non-null  float64\n",
      " 32  31          39961 non-null  float64\n",
      " 33  32          39961 non-null  float64\n",
      " 34  33          39961 non-null  float64\n",
      " 35  34          39961 non-null  float64\n",
      " 36  35          39961 non-null  float64\n",
      " 37  36          39961 non-null  float64\n",
      " 38  37          39961 non-null  float64\n",
      " 39  38          39961 non-null  float64\n",
      " 40  39          39961 non-null  float64\n",
      " 41  40          39961 non-null  float64\n",
      " 42  41          39961 non-null  float64\n",
      " 43  42          39961 non-null  float64\n",
      " 44  43          39961 non-null  float64\n",
      " 45  44          39961 non-null  float64\n",
      " 46  45          39961 non-null  float64\n",
      " 47  46          39961 non-null  float64\n",
      " 48  47          39961 non-null  float64\n",
      " 49  48          39961 non-null  float64\n",
      " 50  49          39961 non-null  float64\n",
      " 51  50          39961 non-null  float64\n",
      " 52  51          39961 non-null  float64\n",
      " 53  52          39961 non-null  float64\n",
      " 54  53          39961 non-null  float64\n",
      " 55  54          39961 non-null  float64\n",
      " 56  55          39961 non-null  float64\n",
      " 57  56          39961 non-null  float64\n",
      " 58  label       39961 non-null  int64  \n",
      "dtypes: float64(57), int64(2)\n",
      "memory usage: 18.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "c1FdOg7F8Nb2"
   },
   "outputs": [],
   "source": [
    "dataset = df.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "gcPxWARG82YV",
    "outputId": "9203a5e3-f932-4f60-bfff-dccaf78718ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.007865</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.175039</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.038711</td>\n",
       "      <td>0.032867</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.024988</td>\n",
       "      <td>0.038540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016935</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.013940</td>\n",
       "      <td>-0.020445</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.044682</td>\n",
       "      <td>-0.379891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.012523</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.150387</td>\n",
       "      <td>0.046052</td>\n",
       "      <td>0.038885</td>\n",
       "      <td>0.033454</td>\n",
       "      <td>0.034460</td>\n",
       "      <td>0.031195</td>\n",
       "      <td>0.038811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521458</td>\n",
       "      <td>-0.032052</td>\n",
       "      <td>-0.013547</td>\n",
       "      <td>-0.019600</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>0.037082</td>\n",
       "      <td>0.113446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.012561</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.181403</td>\n",
       "      <td>-0.148071</td>\n",
       "      <td>0.038827</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016130</td>\n",
       "      <td>-0.005928</td>\n",
       "      <td>-0.009726</td>\n",
       "      <td>-0.030213</td>\n",
       "      <td>-0.024310</td>\n",
       "      <td>-0.079108</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.162260</td>\n",
       "      <td>1.654544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.007925</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.182106</td>\n",
       "      <td>-0.088925</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.032366</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>0.035610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012172</td>\n",
       "      <td>-0.031993</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.054409</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>0.125792</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>0.265480</td>\n",
       "      <td>-0.443563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.010104</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.158995</td>\n",
       "      <td>0.416657</td>\n",
       "      <td>0.038868</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.034165</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>0.038540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015725</td>\n",
       "      <td>-0.019109</td>\n",
       "      <td>-0.016223</td>\n",
       "      <td>-0.045763</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.077117</td>\n",
       "      <td>-0.290066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.007208 -0.007865  0.007028 -0.175039  0.028868  0.038711  0.032867   \n",
       "1  0.007208 -0.012523  0.007028 -0.150387  0.046052  0.038885  0.033454   \n",
       "2  0.007208 -0.012561  0.007028 -0.181403 -0.148071  0.038827  0.032841   \n",
       "3  0.007208 -0.007925  0.007028 -0.182106 -0.088925  0.036465  0.030983   \n",
       "4  0.007208 -0.010104  0.007028 -0.158995  0.416657  0.038868  0.032841   \n",
       "\n",
       "          7         8         9  ...        48        49        50        51  \\\n",
       "0  0.033783  0.024988  0.038540  ... -0.016935 -0.004814 -0.013940 -0.020445   \n",
       "1  0.034460  0.031195  0.038811  ...  0.521458 -0.032052 -0.013547 -0.019600   \n",
       "2  0.034234  0.024823  0.038647  ... -0.016130 -0.005928 -0.009726 -0.030213   \n",
       "3  0.032366  0.025871  0.035610  ... -0.012172 -0.031993  0.004242  0.054409   \n",
       "4  0.034165  0.024293  0.038540  ... -0.015725 -0.019109 -0.016223 -0.045763   \n",
       "\n",
       "         52        53        54        55        56  label  \n",
       "0 -0.024377 -0.082360 -0.037266 -0.044682 -0.379891      0  \n",
       "1 -0.024377  0.099773 -0.037266  0.037082  0.113446      0  \n",
       "2 -0.024310 -0.079108 -0.037266 -0.162260  1.654544      0  \n",
       "3 -0.024377  0.125792 -0.037266  0.265480 -0.443563      0  \n",
       "4 -0.024377 -0.082360 -0.037266 -0.077117 -0.290066      0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fuQG-KCI-yIx",
    "outputId": "ec48e6ee-3186-4cf9-8a57-63c9504550da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39961 entries, 0 to 39960\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       39961 non-null  float64\n",
      " 1   1       39961 non-null  float64\n",
      " 2   2       39961 non-null  float64\n",
      " 3   3       39961 non-null  float64\n",
      " 4   4       39961 non-null  float64\n",
      " 5   5       39961 non-null  float64\n",
      " 6   6       39961 non-null  float64\n",
      " 7   7       39961 non-null  float64\n",
      " 8   8       39961 non-null  float64\n",
      " 9   9       39961 non-null  float64\n",
      " 10  10      39961 non-null  float64\n",
      " 11  11      39961 non-null  float64\n",
      " 12  12      39961 non-null  float64\n",
      " 13  13      39961 non-null  float64\n",
      " 14  14      39961 non-null  float64\n",
      " 15  15      39961 non-null  float64\n",
      " 16  16      39961 non-null  float64\n",
      " 17  17      39961 non-null  float64\n",
      " 18  18      39961 non-null  float64\n",
      " 19  19      39961 non-null  float64\n",
      " 20  20      39961 non-null  float64\n",
      " 21  21      39961 non-null  float64\n",
      " 22  22      39961 non-null  float64\n",
      " 23  23      39961 non-null  float64\n",
      " 24  24      39961 non-null  float64\n",
      " 25  25      39961 non-null  float64\n",
      " 26  26      39961 non-null  float64\n",
      " 27  27      39961 non-null  float64\n",
      " 28  28      39961 non-null  float64\n",
      " 29  29      39961 non-null  float64\n",
      " 30  30      39961 non-null  float64\n",
      " 31  31      39961 non-null  float64\n",
      " 32  32      39961 non-null  float64\n",
      " 33  33      39961 non-null  float64\n",
      " 34  34      39961 non-null  float64\n",
      " 35  35      39961 non-null  float64\n",
      " 36  36      39961 non-null  float64\n",
      " 37  37      39961 non-null  float64\n",
      " 38  38      39961 non-null  float64\n",
      " 39  39      39961 non-null  float64\n",
      " 40  40      39961 non-null  float64\n",
      " 41  41      39961 non-null  float64\n",
      " 42  42      39961 non-null  float64\n",
      " 43  43      39961 non-null  float64\n",
      " 44  44      39961 non-null  float64\n",
      " 45  45      39961 non-null  float64\n",
      " 46  46      39961 non-null  float64\n",
      " 47  47      39961 non-null  float64\n",
      " 48  48      39961 non-null  float64\n",
      " 49  49      39961 non-null  float64\n",
      " 50  50      39961 non-null  float64\n",
      " 51  51      39961 non-null  float64\n",
      " 52  52      39961 non-null  float64\n",
      " 53  53      39961 non-null  float64\n",
      " 54  54      39961 non-null  float64\n",
      " 55  55      39961 non-null  float64\n",
      " 56  56      39961 non-null  float64\n",
      " 57  label   39961 non-null  int64  \n",
      "dtypes: float64(57), int64(1)\n",
      "memory usage: 17.7 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pXAA8dt98_hJ",
    "outputId": "de6d1f5c-8600-4765-8dc1-38e110389d4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -0.010975\n",
       "1       -0.002331\n",
       "2       -0.016250\n",
       "3       -0.079094\n",
       "4       -0.083763\n",
       "5       -0.002659\n",
       "6        0.004689\n",
       "7        0.005516\n",
       "8        0.015100\n",
       "9       -0.002571\n",
       "10      -0.007000\n",
       "11      -0.110200\n",
       "12       0.010072\n",
       "13      -0.012025\n",
       "14      -0.003768\n",
       "15      -0.005879\n",
       "16       0.005982\n",
       "17      -0.017751\n",
       "18      -0.052064\n",
       "19      -0.000421\n",
       "20      -0.029528\n",
       "21       0.053573\n",
       "22       0.035893\n",
       "23       0.014874\n",
       "24       0.003721\n",
       "25       0.028213\n",
       "26       0.196544\n",
       "27       0.010362\n",
       "28       0.162603\n",
       "29      -0.016250\n",
       "30       0.189781\n",
       "31       0.121446\n",
       "32      -0.025905\n",
       "33      -0.033837\n",
       "34      -0.015229\n",
       "35       0.006013\n",
       "36      -0.006734\n",
       "37       0.021033\n",
       "38       0.092276\n",
       "39       0.016145\n",
       "40       0.015080\n",
       "41       0.000702\n",
       "42      -0.006581\n",
       "43       0.025866\n",
       "44       0.024859\n",
       "45       0.024392\n",
       "46      -0.026744\n",
       "47       0.118433\n",
       "48      -0.007796\n",
       "49      -0.016156\n",
       "50       0.006208\n",
       "51       0.037731\n",
       "52      -0.014423\n",
       "53      -0.002220\n",
       "54       0.004940\n",
       "55       0.037652\n",
       "56      -0.056787\n",
       "label    1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr().label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "89y9fPld9RfK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "KgDp3LKG9ldN"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "H2DzY00r-mPX"
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "uOA41ODNs36u"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FYROHXf2fZlh"
   },
   "outputs": [],
   "source": [
    "def scheduler(epochs, lr):\n",
    "    return lr * tf.math.exp(-0.01)\n",
    "\n",
    "lrs = LearningRateScheduler(scheduler)\n",
    "es = EarlyStopping(monitor = 'val_accuracy', patience = 100)\n",
    "#rlp = ReduceLROnPlateau(monitor='val_accuracy', patience=2, factor=0.2)\n",
    "\n",
    "checkpoint_path = \"/content/drive/My Drive/Financial Analytics/wts/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "checkpoint = ModelCheckpoint(filepath = checkpoint_path,\n",
    "                             save_best_only = True,\n",
    "                             save_weights_only = False,\n",
    "                             verbose = 1,\n",
    "                             monitor = 'val_accuracy')\n",
    "#checkpoint = ModelCheckpoint('/content/drive/My Drive/Financial Analytics/Weights/finacial_model_{epoch:03d}.ckpt',\n",
    " #                            save_best_only=True,\n",
    "  #                           save_weights_only=True,\n",
    "   #                          monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NSD65zSO_CsL"
   },
   "outputs": [],
   "source": [
    "X = dataset.drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "VcFCeicoftuf",
    "outputId": "1a919e8e-1623-4460-eb5c-0fcc3e97f69b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.007865</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.175039</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.038711</td>\n",
       "      <td>0.032867</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.024988</td>\n",
       "      <td>0.038540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780566</td>\n",
       "      <td>-0.016935</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.013940</td>\n",
       "      <td>-0.020445</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.044682</td>\n",
       "      <td>-0.379891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.012523</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.150387</td>\n",
       "      <td>0.046052</td>\n",
       "      <td>0.038885</td>\n",
       "      <td>0.033454</td>\n",
       "      <td>0.034460</td>\n",
       "      <td>0.031195</td>\n",
       "      <td>0.038811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505685</td>\n",
       "      <td>0.521458</td>\n",
       "      <td>-0.032052</td>\n",
       "      <td>-0.013547</td>\n",
       "      <td>-0.019600</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>0.037082</td>\n",
       "      <td>0.113446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.012561</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.181403</td>\n",
       "      <td>-0.148071</td>\n",
       "      <td>0.038827</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918007</td>\n",
       "      <td>-0.016130</td>\n",
       "      <td>-0.005928</td>\n",
       "      <td>-0.009726</td>\n",
       "      <td>-0.030213</td>\n",
       "      <td>-0.024310</td>\n",
       "      <td>-0.079108</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.162260</td>\n",
       "      <td>1.654544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.007925</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.182106</td>\n",
       "      <td>-0.088925</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.032366</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>0.035610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708229</td>\n",
       "      <td>-0.012172</td>\n",
       "      <td>-0.031993</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.054409</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>0.125792</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>0.265480</td>\n",
       "      <td>-0.443563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.010104</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.158995</td>\n",
       "      <td>0.416657</td>\n",
       "      <td>0.038868</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.034165</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>0.038540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335175</td>\n",
       "      <td>-0.015725</td>\n",
       "      <td>-0.019109</td>\n",
       "      <td>-0.016223</td>\n",
       "      <td>-0.045763</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.077117</td>\n",
       "      <td>-0.290066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39956</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.182851</td>\n",
       "      <td>-0.131705</td>\n",
       "      <td>0.036661</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.023019</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382449</td>\n",
       "      <td>-0.017033</td>\n",
       "      <td>-0.027783</td>\n",
       "      <td>-0.006135</td>\n",
       "      <td>0.191123</td>\n",
       "      <td>-0.024329</td>\n",
       "      <td>-0.048303</td>\n",
       "      <td>-0.011602</td>\n",
       "      <td>-0.019291</td>\n",
       "      <td>-0.329352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39957</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.182895</td>\n",
       "      <td>-0.119716</td>\n",
       "      <td>0.036983</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.032569</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>0.036645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290321</td>\n",
       "      <td>-0.017217</td>\n",
       "      <td>-0.029197</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>0.531933</td>\n",
       "      <td>-0.024243</td>\n",
       "      <td>-0.043931</td>\n",
       "      <td>-0.021744</td>\n",
       "      <td>-0.034785</td>\n",
       "      <td>-0.205704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39958</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.048103</td>\n",
       "      <td>0.176397</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987910</td>\n",
       "      <td>-0.017820</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>-0.026220</td>\n",
       "      <td>-0.063531</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.082360</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>-0.036509</td>\n",
       "      <td>-0.360805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39959</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.008278</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>-0.166330</td>\n",
       "      <td>-0.038964</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.030590</td>\n",
       "      <td>0.031627</td>\n",
       "      <td>0.025897</td>\n",
       "      <td>0.039591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.592190</td>\n",
       "      <td>-0.018941</td>\n",
       "      <td>-0.020796</td>\n",
       "      <td>-0.019736</td>\n",
       "      <td>-0.050688</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.060096</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>-0.216671</td>\n",
       "      <td>-0.431634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39960</th>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>-0.141492</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111439</td>\n",
       "      <td>-0.012053</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.017097</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>-0.005178</td>\n",
       "      <td>-0.012737</td>\n",
       "      <td>-0.016289</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>-0.361331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39961 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.007208 -0.007865  0.007028 -0.175039  0.028868  0.038711  0.032867   \n",
       "1      0.007208 -0.012523  0.007028 -0.150387  0.046052  0.038885  0.033454   \n",
       "2      0.007208 -0.012561  0.007028 -0.181403 -0.148071  0.038827  0.032841   \n",
       "3      0.007208 -0.007925  0.007028 -0.182106 -0.088925  0.036465  0.030983   \n",
       "4      0.007208 -0.010104  0.007028 -0.158995  0.416657  0.038868  0.032841   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39956  0.007208  0.006839  0.007028 -0.182851 -0.131705  0.036661  0.032207   \n",
       "39957  0.007208  0.003076  0.007028 -0.182895 -0.119716  0.036983  0.032300   \n",
       "39958  0.007208  0.003660  0.007028 -0.048103  0.176397  0.020637  0.015031   \n",
       "39959  0.007208 -0.008278  0.007028 -0.166330 -0.038964  0.038833  0.030590   \n",
       "39960  0.007208  0.004092  0.007028  0.023787 -0.141492  0.019094  0.015899   \n",
       "\n",
       "              7         8         9  ...        47        48        49  \\\n",
       "0      0.033783  0.024988  0.038540  ...  0.780566 -0.016935 -0.004814   \n",
       "1      0.034460  0.031195  0.038811  ...  0.505685  0.521458 -0.032052   \n",
       "2      0.034234  0.024823  0.038647  ...  0.918007 -0.016130 -0.005928   \n",
       "3      0.032366  0.025871  0.035610  ...  0.708229 -0.012172 -0.031993   \n",
       "4      0.034165  0.024293  0.038540  ...  0.335175 -0.015725 -0.019109   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "39956  0.032183  0.023019  0.036326  ...  0.382449 -0.017033 -0.027783   \n",
       "39957  0.032569  0.023719  0.036645  ...  0.290321 -0.017217 -0.029197   \n",
       "39958  0.014398  0.005987  0.019130  ... -0.987910 -0.017820  0.123967   \n",
       "39959  0.031627  0.025897  0.039591  ... -0.592190 -0.018941 -0.020796   \n",
       "39960  0.016508  0.019678  0.018866  ... -0.111439 -0.012053 -0.005083   \n",
       "\n",
       "             50        51        52        53        54        55        56  \n",
       "0     -0.013940 -0.020445 -0.024377 -0.082360 -0.037266 -0.044682 -0.379891  \n",
       "1     -0.013547 -0.019600 -0.024377  0.099773 -0.037266  0.037082  0.113446  \n",
       "2     -0.009726 -0.030213 -0.024310 -0.079108 -0.037266 -0.162260  1.654544  \n",
       "3      0.004242  0.054409 -0.024377  0.125792 -0.037266  0.265480 -0.443563  \n",
       "4     -0.016223 -0.045763 -0.024377 -0.082360 -0.037266 -0.077117 -0.290066  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "39956 -0.006135  0.191123 -0.024329 -0.048303 -0.011602 -0.019291 -0.329352  \n",
       "39957 -0.003584  0.531933 -0.024243 -0.043931 -0.021744 -0.034785 -0.205704  \n",
       "39958 -0.026220 -0.063531 -0.024377 -0.082360 -0.037266 -0.036509 -0.360805  \n",
       "39959 -0.019736 -0.050688 -0.024377 -0.060096  0.019104 -0.216671 -0.431634  \n",
       "39960 -0.017097  0.093782 -0.005178 -0.012737 -0.016289  0.147700 -0.361331  \n",
       "\n",
       "[39961 rows x 57 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "XDod3P75evJq"
   },
   "outputs": [],
   "source": [
    "y = dataset[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "0bmOAvjhZbqw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRSEpihsZLuo"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tRkCFr_EgRhv",
    "outputId": "b56b29f1-906d-4a36-e7a3-5d42d867e223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 57)                3306      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               29696     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 296,171\n",
      "Trainable params: 296,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(57, input_dim = 57, activation = 'relu'))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "print(model.summary())\n",
    "plot_model(model, to_file = 'model flow.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OuiW33dxhYBE"
   },
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "X5NpzG8IkuXt",
    "outputId": "6c4cb9e2-8eaf-49a2-9bf0-40513775ddf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9718 - val_loss: 0.3956 - val_accuracy: 0.9353\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0909 - accuracy: 0.9693 - val_loss: 0.3639 - val_accuracy: 0.9299\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0809 - accuracy: 0.9717 - val_loss: 0.3775 - val_accuracy: 0.9339\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0855 - accuracy: 0.9721 - val_loss: 0.2992 - val_accuracy: 0.9409\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0699 - accuracy: 0.9756 - val_loss: 0.3213 - val_accuracy: 0.9436\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0743 - accuracy: 0.9725 - val_loss: 0.3159 - val_accuracy: 0.9356\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.9707 - val_loss: 0.2801 - val_accuracy: 0.9333\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9713 - val_loss: 0.2729 - val_accuracy: 0.9389\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0748 - accuracy: 0.9743 - val_loss: 0.3078 - val_accuracy: 0.9383\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0669 - accuracy: 0.9753 - val_loss: 0.3034 - val_accuracy: 0.9373\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0799 - accuracy: 0.9706 - val_loss: 0.2996 - val_accuracy: 0.9343\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0727 - accuracy: 0.9726 - val_loss: 0.2771 - val_accuracy: 0.9366\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0680 - accuracy: 0.9752 - val_loss: 0.2989 - val_accuracy: 0.9373\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0745 - accuracy: 0.9731 - val_loss: 0.2932 - val_accuracy: 0.9393\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9754 - val_loss: 0.2995 - val_accuracy: 0.9406\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0706 - accuracy: 0.9742 - val_loss: 0.2740 - val_accuracy: 0.9376\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.9753 - val_loss: 0.2899 - val_accuracy: 0.9399\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0666 - accuracy: 0.9756 - val_loss: 0.2951 - val_accuracy: 0.9376\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0682 - accuracy: 0.9763 - val_loss: 0.2542 - val_accuracy: 0.9409\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9762 - val_loss: 0.2686 - val_accuracy: 0.9436\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9764 - val_loss: 0.2761 - val_accuracy: 0.9419\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0585 - accuracy: 0.9785 - val_loss: 0.2897 - val_accuracy: 0.9436\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0639 - accuracy: 0.9762 - val_loss: 0.3212 - val_accuracy: 0.9403\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9762 - val_loss: 0.2787 - val_accuracy: 0.9419\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 0.3054 - val_accuracy: 0.9396\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9786 - val_loss: 0.3327 - val_accuracy: 0.9409\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9773 - val_loss: 0.2880 - val_accuracy: 0.9419\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0625 - accuracy: 0.9766 - val_loss: 0.2998 - val_accuracy: 0.9426\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0589 - accuracy: 0.9789 - val_loss: 0.2914 - val_accuracy: 0.9423\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9803 - val_loss: 0.3031 - val_accuracy: 0.9413\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0595 - accuracy: 0.9774 - val_loss: 0.2956 - val_accuracy: 0.9416\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0551 - accuracy: 0.9801 - val_loss: 0.3205 - val_accuracy: 0.9369\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9806 - val_loss: 0.3305 - val_accuracy: 0.9366\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0539 - accuracy: 0.9798 - val_loss: 0.3269 - val_accuracy: 0.9419\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0527 - accuracy: 0.9813 - val_loss: 0.2819 - val_accuracy: 0.9443\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9809 - val_loss: 0.3095 - val_accuracy: 0.9396\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.9798 - val_loss: 0.2824 - val_accuracy: 0.9416\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.2938 - val_accuracy: 0.9419\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9802 - val_loss: 0.2678 - val_accuracy: 0.9469\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0461 - accuracy: 0.9832 - val_loss: 0.3159 - val_accuracy: 0.9453\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0536 - accuracy: 0.9808 - val_loss: 0.3228 - val_accuracy: 0.9403\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0495 - accuracy: 0.9819 - val_loss: 0.3021 - val_accuracy: 0.9453\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 0.3120 - val_accuracy: 0.9439\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.3109 - val_accuracy: 0.9393\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0489 - accuracy: 0.9835 - val_loss: 0.2869 - val_accuracy: 0.9483\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0440 - accuracy: 0.9838 - val_loss: 0.3099 - val_accuracy: 0.9453\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9837 - val_loss: 0.2979 - val_accuracy: 0.9433\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9815 - val_loss: 0.2937 - val_accuracy: 0.9449\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 0.3717 - val_accuracy: 0.9393\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0481 - accuracy: 0.9823 - val_loss: 0.3126 - val_accuracy: 0.9443\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0443 - accuracy: 0.9840 - val_loss: 0.3143 - val_accuracy: 0.9456\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9857 - val_loss: 0.3025 - val_accuracy: 0.9459\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0427 - accuracy: 0.9847 - val_loss: 0.3182 - val_accuracy: 0.9486\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9849 - val_loss: 0.3131 - val_accuracy: 0.9443\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.9858 - val_loss: 0.3487 - val_accuracy: 0.9463\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9844 - val_loss: 0.3333 - val_accuracy: 0.9483\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9856 - val_loss: 0.3420 - val_accuracy: 0.9476\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0402 - accuracy: 0.9854 - val_loss: 0.3377 - val_accuracy: 0.9496\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9861 - val_loss: 0.3338 - val_accuracy: 0.9426\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.9864 - val_loss: 0.3418 - val_accuracy: 0.9453\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9854 - val_loss: 0.3403 - val_accuracy: 0.9433\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9862 - val_loss: 0.3017 - val_accuracy: 0.9463\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9878 - val_loss: 0.3533 - val_accuracy: 0.9436\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0395 - accuracy: 0.9854 - val_loss: 0.3109 - val_accuracy: 0.9483\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.3315 - val_accuracy: 0.9456\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0358 - accuracy: 0.9871 - val_loss: 0.3286 - val_accuracy: 0.9446\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0372 - accuracy: 0.9868 - val_loss: 0.3297 - val_accuracy: 0.9476\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.9875 - val_loss: 0.3201 - val_accuracy: 0.9439\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.9888 - val_loss: 0.3567 - val_accuracy: 0.9463\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0368 - accuracy: 0.9870 - val_loss: 0.3175 - val_accuracy: 0.9466\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0315 - accuracy: 0.9891 - val_loss: 0.3310 - val_accuracy: 0.9483\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.3361 - val_accuracy: 0.9463\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0332 - accuracy: 0.9875 - val_loss: 0.3387 - val_accuracy: 0.9486\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0336 - accuracy: 0.9877 - val_loss: 0.3280 - val_accuracy: 0.9469\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0364 - accuracy: 0.9883 - val_loss: 0.3349 - val_accuracy: 0.9503\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0312 - accuracy: 0.9888 - val_loss: 0.3494 - val_accuracy: 0.9503\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9879 - val_loss: 0.3573 - val_accuracy: 0.9493\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0346 - accuracy: 0.9875 - val_loss: 0.3640 - val_accuracy: 0.9473\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9892 - val_loss: 0.3481 - val_accuracy: 0.9476\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.3552 - val_accuracy: 0.9483\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0302 - accuracy: 0.9892 - val_loss: 0.3491 - val_accuracy: 0.9486\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.3653 - val_accuracy: 0.9423\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.3527 - val_accuracy: 0.9456\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9890 - val_loss: 0.3639 - val_accuracy: 0.9473\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.3678 - val_accuracy: 0.9486\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.3851 - val_accuracy: 0.9489\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.3631 - val_accuracy: 0.9496\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 0.3656 - val_accuracy: 0.9449\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9901 - val_loss: 0.3570 - val_accuracy: 0.9493\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.3666 - val_accuracy: 0.9463\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.3421 - val_accuracy: 0.9513\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.3632 - val_accuracy: 0.9530\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.3608 - val_accuracy: 0.9510\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9901 - val_loss: 0.3692 - val_accuracy: 0.9493\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 0.3823 - val_accuracy: 0.9479\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.3872 - val_accuracy: 0.9466\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.3772 - val_accuracy: 0.9476\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.3553 - val_accuracy: 0.9493\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9912 - val_loss: 0.3578 - val_accuracy: 0.9503\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.4034 - val_accuracy: 0.9483\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.3790 - val_accuracy: 0.9496\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.3730 - val_accuracy: 0.9489\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.3831 - val_accuracy: 0.9499\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9907 - val_loss: 0.3731 - val_accuracy: 0.9476\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0240 - accuracy: 0.9911 - val_loss: 0.3584 - val_accuracy: 0.9516\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.4048 - val_accuracy: 0.9476\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.3806 - val_accuracy: 0.9496\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.4125 - val_accuracy: 0.9486\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.4099 - val_accuracy: 0.9466\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.3843 - val_accuracy: 0.9496\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.9927 - val_loss: 0.3888 - val_accuracy: 0.9499\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.3984 - val_accuracy: 0.9499\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.4030 - val_accuracy: 0.9483\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.3947 - val_accuracy: 0.9503\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.4129 - val_accuracy: 0.9499\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9918 - val_loss: 0.4176 - val_accuracy: 0.9483\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.4186 - val_accuracy: 0.9479\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9922 - val_loss: 0.4241 - val_accuracy: 0.9503\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.4016 - val_accuracy: 0.9469\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.3893 - val_accuracy: 0.9483\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.3864 - val_accuracy: 0.9516\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.4145 - val_accuracy: 0.9473\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.4347 - val_accuracy: 0.9489\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.4266 - val_accuracy: 0.9486\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.4188 - val_accuracy: 0.9476\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 0.4329 - val_accuracy: 0.9479\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.4348 - val_accuracy: 0.9503\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.4377 - val_accuracy: 0.9506\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.4071 - val_accuracy: 0.9496\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 0.3861 - val_accuracy: 0.9520\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.4039 - val_accuracy: 0.9510\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.4238 - val_accuracy: 0.9503\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.4307 - val_accuracy: 0.9476\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.4353 - val_accuracy: 0.9486\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 0.4123 - val_accuracy: 0.9496\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.4193 - val_accuracy: 0.9513\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.4025 - val_accuracy: 0.9489\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.4084 - val_accuracy: 0.9513\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.4210 - val_accuracy: 0.9513\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 0.4399 - val_accuracy: 0.9493\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.4069 - val_accuracy: 0.9523\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.4294 - val_accuracy: 0.9469\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.4087 - val_accuracy: 0.9499\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.4175 - val_accuracy: 0.9499\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.3893 - val_accuracy: 0.9530\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.4100 - val_accuracy: 0.9469\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.4122 - val_accuracy: 0.9489\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.4010 - val_accuracy: 0.9483\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.4141 - val_accuracy: 0.9476\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0183 - accuracy: 0.9935 - val_loss: 0.4252 - val_accuracy: 0.9499\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.4379 - val_accuracy: 0.9510\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.4240 - val_accuracy: 0.9503\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.4324 - val_accuracy: 0.9506\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.4298 - val_accuracy: 0.9510\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9936 - val_loss: 0.4331 - val_accuracy: 0.9513\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.4448 - val_accuracy: 0.9499\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.4557 - val_accuracy: 0.9523\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.4544 - val_accuracy: 0.9513\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.4666 - val_accuracy: 0.9513\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.4723 - val_accuracy: 0.9510\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.4572 - val_accuracy: 0.9510\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.4605 - val_accuracy: 0.9510\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.4447 - val_accuracy: 0.9516\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.4473 - val_accuracy: 0.9516\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.4336 - val_accuracy: 0.9526\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.4356 - val_accuracy: 0.9516\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.4374 - val_accuracy: 0.9540\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.4670 - val_accuracy: 0.9493\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.4545 - val_accuracy: 0.9510\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.4428 - val_accuracy: 0.9513\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.4461 - val_accuracy: 0.9513\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.4394 - val_accuracy: 0.9520\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.4422 - val_accuracy: 0.9520\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.4622 - val_accuracy: 0.9523\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.4452 - val_accuracy: 0.9530\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.4472 - val_accuracy: 0.9543\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.4455 - val_accuracy: 0.9530\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.4467 - val_accuracy: 0.9520\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.4651 - val_accuracy: 0.9506\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.4645 - val_accuracy: 0.9489\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.4527 - val_accuracy: 0.9493\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.4646 - val_accuracy: 0.9510\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.4776 - val_accuracy: 0.9486\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.4620 - val_accuracy: 0.9526\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.4958 - val_accuracy: 0.9483\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.4762 - val_accuracy: 0.9503\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.4675 - val_accuracy: 0.9503\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.4692 - val_accuracy: 0.9526\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.4762 - val_accuracy: 0.9516\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.4710 - val_accuracy: 0.9530\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.4660 - val_accuracy: 0.9520\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.4767 - val_accuracy: 0.9520\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.4825 - val_accuracy: 0.9503\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.4876 - val_accuracy: 0.9523\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.4915 - val_accuracy: 0.9510\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.4970 - val_accuracy: 0.9503\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.5028 - val_accuracy: 0.9520\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.4971 - val_accuracy: 0.9513\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.4994 - val_accuracy: 0.9496\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.4902 - val_accuracy: 0.9520\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.5038 - val_accuracy: 0.9526\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.5025 - val_accuracy: 0.9506\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.4937 - val_accuracy: 0.9523\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.5063 - val_accuracy: 0.9499\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.4987 - val_accuracy: 0.9503\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.5029 - val_accuracy: 0.9513\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.5200 - val_accuracy: 0.9513\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.5103 - val_accuracy: 0.9506\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.5026 - val_accuracy: 0.9513\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.5050 - val_accuracy: 0.9526\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.5013 - val_accuracy: 0.9540\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 0.5062 - val_accuracy: 0.9543\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.5150 - val_accuracy: 0.9526\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.5201 - val_accuracy: 0.9516\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.5167 - val_accuracy: 0.9516\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.5135 - val_accuracy: 0.9523\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.5226 - val_accuracy: 0.9520\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.5193 - val_accuracy: 0.9550\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.5423 - val_accuracy: 0.9516\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0118 - accuracy: 0.9955 - val_loss: 0.5258 - val_accuracy: 0.9530\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.5140 - val_accuracy: 0.9533\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.5165 - val_accuracy: 0.9533\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.5124 - val_accuracy: 0.9526\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.5267 - val_accuracy: 0.9526\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.5222 - val_accuracy: 0.9520\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.5337 - val_accuracy: 0.9530\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.5516 - val_accuracy: 0.9503\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.5492 - val_accuracy: 0.9530\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.5368 - val_accuracy: 0.9530\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.5438 - val_accuracy: 0.9526\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 0.5578 - val_accuracy: 0.9516\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.5483 - val_accuracy: 0.9513\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.5585 - val_accuracy: 0.9503\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.5345 - val_accuracy: 0.9533\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.5339 - val_accuracy: 0.9510\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.5148 - val_accuracy: 0.9533\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.4989 - val_accuracy: 0.9533\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 0.5232 - val_accuracy: 0.9499\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.5135 - val_accuracy: 0.9499\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.5255 - val_accuracy: 0.9523\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.5182 - val_accuracy: 0.9516\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.5190 - val_accuracy: 0.9523\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.5168 - val_accuracy: 0.9513\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.5184 - val_accuracy: 0.9520\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.5336 - val_accuracy: 0.9516\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.5395 - val_accuracy: 0.9526\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.5436 - val_accuracy: 0.9526\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.5235 - val_accuracy: 0.9540\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.5378 - val_accuracy: 0.9540\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.5414 - val_accuracy: 0.9536\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.5433 - val_accuracy: 0.9523\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.5478 - val_accuracy: 0.9546\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.5398 - val_accuracy: 0.9513\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.5297 - val_accuracy: 0.9536\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.5333 - val_accuracy: 0.9526\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.5394 - val_accuracy: 0.9530\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.5341 - val_accuracy: 0.9526\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.5437 - val_accuracy: 0.9523\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.5416 - val_accuracy: 0.9530\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9967 - val_loss: 0.5431 - val_accuracy: 0.9513\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.5440 - val_accuracy: 0.9523\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.5348 - val_accuracy: 0.9516\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.5547 - val_accuracy: 0.9516\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5610 - val_accuracy: 0.9506\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.5516 - val_accuracy: 0.9503\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.5571 - val_accuracy: 0.9520\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.5561 - val_accuracy: 0.9526\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.5605 - val_accuracy: 0.9503\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.5547 - val_accuracy: 0.9516\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.5618 - val_accuracy: 0.9516\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.5584 - val_accuracy: 0.9533\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.5650 - val_accuracy: 0.9523\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.5607 - val_accuracy: 0.9540\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.5544 - val_accuracy: 0.9550\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.5602 - val_accuracy: 0.9533\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.5637 - val_accuracy: 0.9510\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.5705 - val_accuracy: 0.9533\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.5615 - val_accuracy: 0.9536\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.5586 - val_accuracy: 0.9526\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.5750 - val_accuracy: 0.9513\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.5613 - val_accuracy: 0.9533\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.5698 - val_accuracy: 0.9530\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.5654 - val_accuracy: 0.9546\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.5677 - val_accuracy: 0.9536\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.5655 - val_accuracy: 0.9533\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.5686 - val_accuracy: 0.9516\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.5605 - val_accuracy: 0.9523\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.5555 - val_accuracy: 0.9533\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.5650 - val_accuracy: 0.9520\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.5609 - val_accuracy: 0.9530\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.5620 - val_accuracy: 0.9530\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.5650 - val_accuracy: 0.9523\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.5738 - val_accuracy: 0.9546\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.5776 - val_accuracy: 0.9546\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.5925 - val_accuracy: 0.9530\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.5830 - val_accuracy: 0.9530\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.5762 - val_accuracy: 0.9520\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.5750 - val_accuracy: 0.9530\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.5758 - val_accuracy: 0.9523\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.5839 - val_accuracy: 0.9523\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.5824 - val_accuracy: 0.9523\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.5769 - val_accuracy: 0.9540\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.5701 - val_accuracy: 0.9536\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.5795 - val_accuracy: 0.9533\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.5748 - val_accuracy: 0.9530\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.5762 - val_accuracy: 0.9533\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.5849 - val_accuracy: 0.9526\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.5842 - val_accuracy: 0.9540\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.5840 - val_accuracy: 0.9540\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.5788 - val_accuracy: 0.9533\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.5857 - val_accuracy: 0.9540\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.5827 - val_accuracy: 0.9543\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.5869 - val_accuracy: 0.9520\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.5807 - val_accuracy: 0.9543\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.5796 - val_accuracy: 0.9536\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.5812 - val_accuracy: 0.9536\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.5723 - val_accuracy: 0.9536\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.5834 - val_accuracy: 0.9530\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.5961 - val_accuracy: 0.9513\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.5972 - val_accuracy: 0.9526\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.5905 - val_accuracy: 0.9530\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.5867 - val_accuracy: 0.9543\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.5917 - val_accuracy: 0.9533\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.5918 - val_accuracy: 0.9526\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.5934 - val_accuracy: 0.9516\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.5899 - val_accuracy: 0.9520\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.5946 - val_accuracy: 0.9513\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.5965 - val_accuracy: 0.9513\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.5909 - val_accuracy: 0.9523\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.5928 - val_accuracy: 0.9523\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5892 - val_accuracy: 0.9520\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.5935 - val_accuracy: 0.9526\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.6020 - val_accuracy: 0.9510\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.5991 - val_accuracy: 0.9520\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.6015 - val_accuracy: 0.9510\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.6024 - val_accuracy: 0.9503\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.5999 - val_accuracy: 0.9523\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.5988 - val_accuracy: 0.9523\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.6062 - val_accuracy: 0.9513\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.6081 - val_accuracy: 0.9520\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.6028 - val_accuracy: 0.9506\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.6016 - val_accuracy: 0.9516\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.5991 - val_accuracy: 0.9516\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.6053 - val_accuracy: 0.9506\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.6056 - val_accuracy: 0.9526\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.6075 - val_accuracy: 0.9513\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5978 - val_accuracy: 0.9516\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.6026 - val_accuracy: 0.9513\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.6100 - val_accuracy: 0.9520\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6065 - val_accuracy: 0.9520\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.6017 - val_accuracy: 0.9520\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.5996 - val_accuracy: 0.9516\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.6027 - val_accuracy: 0.9520\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.6000 - val_accuracy: 0.9516\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.5873 - val_accuracy: 0.9536\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.5957 - val_accuracy: 0.9526\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.5974 - val_accuracy: 0.9520\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.5955 - val_accuracy: 0.9516\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.6025 - val_accuracy: 0.9523\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.6028 - val_accuracy: 0.9520\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.6014 - val_accuracy: 0.9520\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.6010 - val_accuracy: 0.9523\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.6063 - val_accuracy: 0.9536\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.6041 - val_accuracy: 0.9526\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.6098 - val_accuracy: 0.9530\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.6050 - val_accuracy: 0.9530\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.6075 - val_accuracy: 0.9530\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.6104 - val_accuracy: 0.9536\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.6046 - val_accuracy: 0.9523\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.6064 - val_accuracy: 0.9526\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.6021 - val_accuracy: 0.9533\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.6003 - val_accuracy: 0.9540\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.5978 - val_accuracy: 0.9540\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.5951 - val_accuracy: 0.9536\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.6033 - val_accuracy: 0.9530\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.6003 - val_accuracy: 0.9530\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6030 - val_accuracy: 0.9533\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.6041 - val_accuracy: 0.9520\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.6066 - val_accuracy: 0.9533\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.6108 - val_accuracy: 0.9526\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.6084 - val_accuracy: 0.9543\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.6074 - val_accuracy: 0.9546\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.5971 - val_accuracy: 0.9540\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.6028 - val_accuracy: 0.9533\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.6030 - val_accuracy: 0.9536\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6043 - val_accuracy: 0.9536\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.6024 - val_accuracy: 0.9526\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.6013 - val_accuracy: 0.9526\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: 0.5927 - val_accuracy: 0.9530\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.5974 - val_accuracy: 0.9533\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.5964 - val_accuracy: 0.9536\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.5969 - val_accuracy: 0.9536\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.5991 - val_accuracy: 0.9536\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.5983 - val_accuracy: 0.9536\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.6011 - val_accuracy: 0.9533\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.6001 - val_accuracy: 0.9540\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.5989 - val_accuracy: 0.9526\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.6010 - val_accuracy: 0.9526\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.6017 - val_accuracy: 0.9530\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.5994 - val_accuracy: 0.9520\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.6026 - val_accuracy: 0.9526\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.5979 - val_accuracy: 0.9540\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.5974 - val_accuracy: 0.9523\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.5992 - val_accuracy: 0.9516\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.5980 - val_accuracy: 0.9526\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.5999 - val_accuracy: 0.9530\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.6014 - val_accuracy: 0.9526\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.5977 - val_accuracy: 0.9526\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.5966 - val_accuracy: 0.9536\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.5969 - val_accuracy: 0.9526\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.5954 - val_accuracy: 0.9536\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.5993 - val_accuracy: 0.9523\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.5994 - val_accuracy: 0.9530\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.5985 - val_accuracy: 0.9536\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.5978 - val_accuracy: 0.9530\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.5975 - val_accuracy: 0.9543\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.5981 - val_accuracy: 0.9533\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.5960 - val_accuracy: 0.9540\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.5978 - val_accuracy: 0.9536\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.6022 - val_accuracy: 0.9533\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6023 - val_accuracy: 0.9533\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6036 - val_accuracy: 0.9536\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.5992 - val_accuracy: 0.9536\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.6019 - val_accuracy: 0.9536\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.6042 - val_accuracy: 0.9533\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.6041 - val_accuracy: 0.9536\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.6047 - val_accuracy: 0.9536\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.6055 - val_accuracy: 0.9526\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.6056 - val_accuracy: 0.9530\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.6047 - val_accuracy: 0.9530\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.6056 - val_accuracy: 0.9530\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.6048 - val_accuracy: 0.9523\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6057 - val_accuracy: 0.9520\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.6067 - val_accuracy: 0.9523\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.6026 - val_accuracy: 0.9530\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.6050 - val_accuracy: 0.9536\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.6055 - val_accuracy: 0.9536\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.6040 - val_accuracy: 0.9536\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.6082 - val_accuracy: 0.9533\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6098 - val_accuracy: 0.9540\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.6077 - val_accuracy: 0.9536\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.6087 - val_accuracy: 0.9536\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6093 - val_accuracy: 0.9530\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.6080 - val_accuracy: 0.9530\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.6073 - val_accuracy: 0.9533\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.6047 - val_accuracy: 0.9550\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6064 - val_accuracy: 0.9540\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.5998 - val_accuracy: 0.9540\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.6004 - val_accuracy: 0.9546\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.5996 - val_accuracy: 0.9546\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.6017 - val_accuracy: 0.9543\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.6034 - val_accuracy: 0.9536\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.6026 - val_accuracy: 0.9523\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.6039 - val_accuracy: 0.9526\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.6015 - val_accuracy: 0.9533\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6030 - val_accuracy: 0.9536\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.6022 - val_accuracy: 0.9526\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.6036 - val_accuracy: 0.9523\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.6036 - val_accuracy: 0.9526\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.6039 - val_accuracy: 0.9526\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.6043 - val_accuracy: 0.9523\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.6073 - val_accuracy: 0.9533\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.6074 - val_accuracy: 0.9533\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.6078 - val_accuracy: 0.9530\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.6052 - val_accuracy: 0.9533\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.6056 - val_accuracy: 0.9530\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.6047 - val_accuracy: 0.9530\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6024 - val_accuracy: 0.9533\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6044 - val_accuracy: 0.9533\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.6039 - val_accuracy: 0.9526\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.6053 - val_accuracy: 0.9530\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.6066 - val_accuracy: 0.9536\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.6075 - val_accuracy: 0.9533\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.6097 - val_accuracy: 0.9540\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6086 - val_accuracy: 0.9536\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.6091 - val_accuracy: 0.9530\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.6099 - val_accuracy: 0.9543\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.6113 - val_accuracy: 0.9533\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.6135 - val_accuracy: 0.9533\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.6152 - val_accuracy: 0.9533\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.6135 - val_accuracy: 0.9533\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6168 - val_accuracy: 0.9536\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.6184 - val_accuracy: 0.9536\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.6189 - val_accuracy: 0.9533\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6160 - val_accuracy: 0.9536\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.6159 - val_accuracy: 0.9536\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.6171 - val_accuracy: 0.9536\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.6151 - val_accuracy: 0.9536\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.6149 - val_accuracy: 0.9536\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.6179 - val_accuracy: 0.9530\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6194 - val_accuracy: 0.9536\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.6200 - val_accuracy: 0.9526\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.6184 - val_accuracy: 0.9536\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.6191 - val_accuracy: 0.9530\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.6192 - val_accuracy: 0.9533\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.6168 - val_accuracy: 0.9530\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.6164 - val_accuracy: 0.9530\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6169 - val_accuracy: 0.9533\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.6184 - val_accuracy: 0.9530\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.6185 - val_accuracy: 0.9536\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.6177 - val_accuracy: 0.9543\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.6194 - val_accuracy: 0.9536\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6192 - val_accuracy: 0.9533\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6203 - val_accuracy: 0.9523\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.6211 - val_accuracy: 0.9523\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.6205 - val_accuracy: 0.9530\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.6204 - val_accuracy: 0.9533\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.6194 - val_accuracy: 0.9530\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6191 - val_accuracy: 0.9533\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.6205 - val_accuracy: 0.9526\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.6221 - val_accuracy: 0.9526\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6208 - val_accuracy: 0.9530\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.6225 - val_accuracy: 0.9533\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.6213 - val_accuracy: 0.9533\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.6211 - val_accuracy: 0.9533\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.6212 - val_accuracy: 0.9530\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.6208 - val_accuracy: 0.9526\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.6212 - val_accuracy: 0.9530\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.6202 - val_accuracy: 0.9533\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.6201 - val_accuracy: 0.9533\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.6195 - val_accuracy: 0.9533\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.6205 - val_accuracy: 0.9536\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.6202 - val_accuracy: 0.9533\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.6199 - val_accuracy: 0.9533\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.6211 - val_accuracy: 0.9533\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.6214 - val_accuracy: 0.9533\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.6221 - val_accuracy: 0.9533\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.6219 - val_accuracy: 0.9533\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.6221 - val_accuracy: 0.9536\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.6211 - val_accuracy: 0.9533\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.6224 - val_accuracy: 0.9533\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.6227 - val_accuracy: 0.9530\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.6202 - val_accuracy: 0.9533\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.6188 - val_accuracy: 0.9533\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.6194 - val_accuracy: 0.9536\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.6206 - val_accuracy: 0.9533\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.6223 - val_accuracy: 0.9530\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6216 - val_accuracy: 0.9536\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.6218 - val_accuracy: 0.9536\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.6222 - val_accuracy: 0.9533\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6217 - val_accuracy: 0.9536\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.6230 - val_accuracy: 0.9533\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.6236 - val_accuracy: 0.9536\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.6234 - val_accuracy: 0.9533\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.6239 - val_accuracy: 0.9533\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.6239 - val_accuracy: 0.9536\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.6225 - val_accuracy: 0.9540\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6224 - val_accuracy: 0.9536\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.6234 - val_accuracy: 0.9540\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.6229 - val_accuracy: 0.9536\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.6222 - val_accuracy: 0.9536\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.6228 - val_accuracy: 0.9536\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.6229 - val_accuracy: 0.9533\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.6246 - val_accuracy: 0.9533\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6247 - val_accuracy: 0.9530\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6249 - val_accuracy: 0.9536\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.6236 - val_accuracy: 0.9540\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.6236 - val_accuracy: 0.9533\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.6237 - val_accuracy: 0.9536\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.6241 - val_accuracy: 0.9536\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6251 - val_accuracy: 0.9530\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.6249 - val_accuracy: 0.9530\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.6248 - val_accuracy: 0.9530\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.6248 - val_accuracy: 0.9530\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.6237 - val_accuracy: 0.9533\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.6239 - val_accuracy: 0.9533\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.6231 - val_accuracy: 0.9533\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6243 - val_accuracy: 0.9533\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.6247 - val_accuracy: 0.9533\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.6241 - val_accuracy: 0.9533\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.6228 - val_accuracy: 0.9530\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.6223 - val_accuracy: 0.9530\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6218 - val_accuracy: 0.9536\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.6223 - val_accuracy: 0.9533\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.6233 - val_accuracy: 0.9533\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6238 - val_accuracy: 0.9533\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.6243 - val_accuracy: 0.9533\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.6244 - val_accuracy: 0.9530\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6250 - val_accuracy: 0.9530\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.6247 - val_accuracy: 0.9530\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.6246 - val_accuracy: 0.9530\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.6243 - val_accuracy: 0.9530\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.6247 - val_accuracy: 0.9530\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6244 - val_accuracy: 0.9530\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6240 - val_accuracy: 0.9530\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.6238 - val_accuracy: 0.9533\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6236 - val_accuracy: 0.9530\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.6236 - val_accuracy: 0.9533\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.6242 - val_accuracy: 0.9533\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.6246 - val_accuracy: 0.9533\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.6241 - val_accuracy: 0.9533\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6242 - val_accuracy: 0.9533\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.6246 - val_accuracy: 0.9530\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.6251 - val_accuracy: 0.9530\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6249 - val_accuracy: 0.9530\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.6240 - val_accuracy: 0.9530\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.6238 - val_accuracy: 0.9530\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.6229 - val_accuracy: 0.9530\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.6225 - val_accuracy: 0.9530\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6228 - val_accuracy: 0.9530\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.6236 - val_accuracy: 0.9530\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.6237 - val_accuracy: 0.9530\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.6229 - val_accuracy: 0.9530\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.6232 - val_accuracy: 0.9530\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.6233 - val_accuracy: 0.9530\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.6224 - val_accuracy: 0.9530\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.6227 - val_accuracy: 0.9530\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.6227 - val_accuracy: 0.9526\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.6227 - val_accuracy: 0.9526\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.6228 - val_accuracy: 0.9526\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.6243 - val_accuracy: 0.9526\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.6245 - val_accuracy: 0.9526\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6246 - val_accuracy: 0.9526\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.6237 - val_accuracy: 0.9526\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.6235 - val_accuracy: 0.9526\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.6234 - val_accuracy: 0.9530\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.6236 - val_accuracy: 0.9530\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.6233 - val_accuracy: 0.9530\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.6241 - val_accuracy: 0.9530\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.6242 - val_accuracy: 0.9530\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.6245 - val_accuracy: 0.9530\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.6243 - val_accuracy: 0.9526\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.6233 - val_accuracy: 0.9526\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6235 - val_accuracy: 0.9526\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6237 - val_accuracy: 0.9526\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.6240 - val_accuracy: 0.9526\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.6238 - val_accuracy: 0.9526\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.6236 - val_accuracy: 0.9526\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.6235 - val_accuracy: 0.9526\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.6237 - val_accuracy: 0.9526\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.6236 - val_accuracy: 0.9526\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.6241 - val_accuracy: 0.9526\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.6241 - val_accuracy: 0.9526\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.6243 - val_accuracy: 0.9526\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.6241 - val_accuracy: 0.9526\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.6240 - val_accuracy: 0.9526\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.6246 - val_accuracy: 0.9526\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.6245 - val_accuracy: 0.9526\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.6243 - val_accuracy: 0.9526\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.6244 - val_accuracy: 0.9526\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.6246 - val_accuracy: 0.9526\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.6243 - val_accuracy: 0.9526\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.6240 - val_accuracy: 0.9526\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6238 - val_accuracy: 0.9526\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.6239 - val_accuracy: 0.9526\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.6234 - val_accuracy: 0.9526\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.6232 - val_accuracy: 0.9526\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6227 - val_accuracy: 0.9526\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.6230 - val_accuracy: 0.9530\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.6230 - val_accuracy: 0.9530\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6226 - val_accuracy: 0.9526\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.6230 - val_accuracy: 0.9526\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.6230 - val_accuracy: 0.9526\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6232 - val_accuracy: 0.9530\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.6233 - val_accuracy: 0.9530\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.6230 - val_accuracy: 0.9526\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.6230 - val_accuracy: 0.9526\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.6229 - val_accuracy: 0.9526\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.6231 - val_accuracy: 0.9530\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6231 - val_accuracy: 0.9526\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6234 - val_accuracy: 0.9526\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.6236 - val_accuracy: 0.9526\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.6236 - val_accuracy: 0.9526\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.6238 - val_accuracy: 0.9530\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.6238 - val_accuracy: 0.9530\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.6238 - val_accuracy: 0.9530\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.6233 - val_accuracy: 0.9530\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6230 - val_accuracy: 0.9530\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.6230 - val_accuracy: 0.9526\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.6232 - val_accuracy: 0.9526\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.6236 - val_accuracy: 0.9526\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.6239 - val_accuracy: 0.9526\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.6239 - val_accuracy: 0.9526\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6239 - val_accuracy: 0.9526\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.6235 - val_accuracy: 0.9530\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.6235 - val_accuracy: 0.9530\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.6234 - val_accuracy: 0.9530\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.6232 - val_accuracy: 0.9530\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.6235 - val_accuracy: 0.9530\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.6238 - val_accuracy: 0.9530\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6233 - val_accuracy: 0.9533\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.6235 - val_accuracy: 0.9530\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6235 - val_accuracy: 0.9530\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.6233 - val_accuracy: 0.9533\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.6237 - val_accuracy: 0.9533\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.6236 - val_accuracy: 0.9530\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6240 - val_accuracy: 0.9530\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.6240 - val_accuracy: 0.9530\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.6240 - val_accuracy: 0.9530\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6241 - val_accuracy: 0.9530\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.6240 - val_accuracy: 0.9530\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.6240 - val_accuracy: 0.9530\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.6242 - val_accuracy: 0.9530\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.6243 - val_accuracy: 0.9530\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6242 - val_accuracy: 0.9530\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.6245 - val_accuracy: 0.9530\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.6247 - val_accuracy: 0.9530\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.6249 - val_accuracy: 0.9530\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.6249 - val_accuracy: 0.9530\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.6247 - val_accuracy: 0.9530\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.6248 - val_accuracy: 0.9530\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.6247 - val_accuracy: 0.9530\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.6247 - val_accuracy: 0.9530\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.6244 - val_accuracy: 0.9530\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.6244 - val_accuracy: 0.9530\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.6243 - val_accuracy: 0.9530\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6243 - val_accuracy: 0.9530\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.6244 - val_accuracy: 0.9530\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.6243 - val_accuracy: 0.9530\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.6245 - val_accuracy: 0.9533\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6245 - val_accuracy: 0.9533\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.6245 - val_accuracy: 0.9533\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.6245 - val_accuracy: 0.9533\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6244 - val_accuracy: 0.9533\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6244 - val_accuracy: 0.9533\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.6241 - val_accuracy: 0.9533\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.6242 - val_accuracy: 0.9533\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.6246 - val_accuracy: 0.9533\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6245 - val_accuracy: 0.9530\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.6245 - val_accuracy: 0.9530\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.6247 - val_accuracy: 0.9533\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.6245 - val_accuracy: 0.9533\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.6248 - val_accuracy: 0.9533\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.6247 - val_accuracy: 0.9533\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.6245 - val_accuracy: 0.9533\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.6246 - val_accuracy: 0.9533\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.6247 - val_accuracy: 0.9533\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.6249 - val_accuracy: 0.9533\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.6248 - val_accuracy: 0.9533\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6248 - val_accuracy: 0.9533\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.6249 - val_accuracy: 0.9533\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6251 - val_accuracy: 0.9530\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.6252 - val_accuracy: 0.9533\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.6252 - val_accuracy: 0.9533\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.6253 - val_accuracy: 0.9533\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9533\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.6252 - val_accuracy: 0.9533\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.6253 - val_accuracy: 0.9533\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.6255 - val_accuracy: 0.9533\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.6256 - val_accuracy: 0.9533\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.6254 - val_accuracy: 0.9533\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9533\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.6254 - val_accuracy: 0.9533\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6254 - val_accuracy: 0.9533\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.6254 - val_accuracy: 0.9533\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.6252 - val_accuracy: 0.9533\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.6252 - val_accuracy: 0.9533\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.6250 - val_accuracy: 0.9533\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.6250 - val_accuracy: 0.9533\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.6249 - val_accuracy: 0.9536\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6248 - val_accuracy: 0.9536\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6248 - val_accuracy: 0.9536\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6248 - val_accuracy: 0.9536\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.6250 - val_accuracy: 0.9536\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6252 - val_accuracy: 0.9533\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.6250 - val_accuracy: 0.9533\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.6252 - val_accuracy: 0.9533\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.6252 - val_accuracy: 0.9533\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.6252 - val_accuracy: 0.9533\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.6252 - val_accuracy: 0.9533\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6251 - val_accuracy: 0.9533\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.6250 - val_accuracy: 0.9533\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.6250 - val_accuracy: 0.9533\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6250 - val_accuracy: 0.9533\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.6250 - val_accuracy: 0.9533\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6250 - val_accuracy: 0.9533\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.6249 - val_accuracy: 0.9533\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.6248 - val_accuracy: 0.9533\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6249 - val_accuracy: 0.9533\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.6249 - val_accuracy: 0.9533\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6250 - val_accuracy: 0.9530\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.6251 - val_accuracy: 0.9530\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.6251 - val_accuracy: 0.9530\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.6251 - val_accuracy: 0.9530\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.6252 - val_accuracy: 0.9530\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6255 - val_accuracy: 0.9530\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.6257 - val_accuracy: 0.9526\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6257 - val_accuracy: 0.9526\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.6257 - val_accuracy: 0.9526\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6257 - val_accuracy: 0.9526\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.6257 - val_accuracy: 0.9530\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.6257 - val_accuracy: 0.9530\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.6257 - val_accuracy: 0.9530\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.6258 - val_accuracy: 0.9526\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6259 - val_accuracy: 0.9526\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.6260 - val_accuracy: 0.9526\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.6260 - val_accuracy: 0.9526\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.6260 - val_accuracy: 0.9526\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6260 - val_accuracy: 0.9530\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6260 - val_accuracy: 0.9530\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9981 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.6259 - val_accuracy: 0.9530\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6257 - val_accuracy: 0.9530\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.6258 - val_accuracy: 0.9530\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.6257 - val_accuracy: 0.9530\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.6257 - val_accuracy: 0.9530\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6257 - val_accuracy: 0.9530\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.6257 - val_accuracy: 0.9530\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.6255 - val_accuracy: 0.9530\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.6255 - val_accuracy: 0.9530\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.6255 - val_accuracy: 0.9530\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6255 - val_accuracy: 0.9530\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.6255 - val_accuracy: 0.9530\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6256 - val_accuracy: 0.9530\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6255 - val_accuracy: 0.9530\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.6255 - val_accuracy: 0.9530\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.6255 - val_accuracy: 0.9530\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.6255 - val_accuracy: 0.9530\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6254 - val_accuracy: 0.9530\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.6253 - val_accuracy: 0.9530\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.6253 - val_accuracy: 0.9530\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit(X,y,epochs=100,batch_size=32) -> 99.45\n",
    "history = model.fit(X_train , y_train, validation_split = 0.1 , validation_data = (X_test, y_test), epochs = 1000, batch_size = 100, callbacks = [lrs, checkpoint])\n",
    "#validation_data=(X_test,y_test)\n",
    "#,callbacks=[lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ipRk9U1Ek_cS",
    "outputId": "854f8086-546b-4e1c-c9e4-1eea972f3318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.46\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "i, accuracy = model.evaluate(X_test, y_test,verbose = 0)\n",
    "print('Accuracy: %.2f' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "m1girCfssGKC",
    "outputId": "77089037-94cf-478b-8952-fc373eed3670"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = \"training\")\n",
    "#plt.plot(hist.history['loss'])\n",
    "#plt.show()\n",
    "\n",
    "plt.plot(history.history['val_loss'], label = 'validation')\n",
    "#plt.plot(hist.history['loss'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 993
    },
    "id": "XfvTFIJ4nQJt",
    "outputId": "388fd925-66da-452e-d5c8-faa47bb32ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               7424      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 24,197\n",
      "Trainable params: 24,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim = 57, activation = 'relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation = 'relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "print(model.summary())\n",
    "plot_model(model, to_file = 'model flow.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrEQuXhLo6QX"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5KknEvvgpFrP",
    "outputId": "40f0088d-07e1-4ac5-951e-2cfc9bd21052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "946/956 [============================>.] - ETA: 0s - loss: 0.5929 - accuracy: 0.7303\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77304, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.5923 - accuracy: 0.7309 - val_loss: 0.5364 - val_accuracy: 0.7730\n",
      "Epoch 2/150\n",
      "941/956 [============================>.] - ETA: 0s - loss: 0.4967 - accuracy: 0.7920\n",
      "Epoch 00002: val_accuracy improved from 0.77304 to 0.79659, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.4960 - accuracy: 0.7924 - val_loss: 0.4761 - val_accuracy: 0.7966\n",
      "Epoch 3/150\n",
      "951/956 [============================>.] - ETA: 0s - loss: 0.4526 - accuracy: 0.8100\n",
      "Epoch 00003: val_accuracy improved from 0.79659 to 0.81572, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.4526 - accuracy: 0.8100 - val_loss: 0.4428 - val_accuracy: 0.8157\n",
      "Epoch 4/150\n",
      "950/956 [============================>.] - ETA: 0s - loss: 0.4285 - accuracy: 0.8208\n",
      "Epoch 00004: val_accuracy improved from 0.81572 to 0.82396, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.4282 - accuracy: 0.8209 - val_loss: 0.4217 - val_accuracy: 0.8240\n",
      "Epoch 5/150\n",
      "936/956 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8296\n",
      "Epoch 00005: val_accuracy improved from 0.82396 to 0.83014, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.4078 - accuracy: 0.8299 - val_loss: 0.4081 - val_accuracy: 0.8301\n",
      "Epoch 6/150\n",
      "938/956 [============================>.] - ETA: 0s - loss: 0.3966 - accuracy: 0.8384\n",
      "Epoch 00006: val_accuracy improved from 0.83014 to 0.83721, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.3960 - accuracy: 0.8386 - val_loss: 0.3938 - val_accuracy: 0.8372\n",
      "Epoch 7/150\n",
      "950/956 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8458\n",
      "Epoch 00007: val_accuracy improved from 0.83721 to 0.83780, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.3805 - accuracy: 0.8458 - val_loss: 0.3917 - val_accuracy: 0.8378\n",
      "Epoch 8/150\n",
      "948/956 [============================>.] - ETA: 0s - loss: 0.3705 - accuracy: 0.8501\n",
      "Epoch 00008: val_accuracy improved from 0.83780 to 0.85016, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.3706 - accuracy: 0.8502 - val_loss: 0.3747 - val_accuracy: 0.8502\n",
      "Epoch 9/150\n",
      "936/956 [============================>.] - ETA: 0s - loss: 0.3643 - accuracy: 0.8520\n",
      "Epoch 00009: val_accuracy improved from 0.85016 to 0.85046, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.3646 - accuracy: 0.8518 - val_loss: 0.3618 - val_accuracy: 0.8505\n",
      "Epoch 10/150\n",
      "941/956 [============================>.] - ETA: 0s - loss: 0.3520 - accuracy: 0.8589\n",
      "Epoch 00010: val_accuracy improved from 0.85046 to 0.86400, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.3522 - accuracy: 0.8589 - val_loss: 0.3494 - val_accuracy: 0.8640\n",
      "Epoch 11/150\n",
      "954/956 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.8633\n",
      "Epoch 00011: val_accuracy improved from 0.86400 to 0.86518, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.3427 - accuracy: 0.8633 - val_loss: 0.3428 - val_accuracy: 0.8652\n",
      "Epoch 12/150\n",
      "940/956 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.8648\n",
      "Epoch 00012: val_accuracy improved from 0.86518 to 0.87283, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.3349 - accuracy: 0.8650 - val_loss: 0.3277 - val_accuracy: 0.8728\n",
      "Epoch 13/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.3265 - accuracy: 0.8683\n",
      "Epoch 00013: val_accuracy did not improve from 0.87283\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.3262 - accuracy: 0.8684 - val_loss: 0.3338 - val_accuracy: 0.8637\n",
      "Epoch 14/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.3165 - accuracy: 0.8728\n",
      "Epoch 00014: val_accuracy improved from 0.87283 to 0.87489, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.3172 - accuracy: 0.8724 - val_loss: 0.3225 - val_accuracy: 0.8749\n",
      "Epoch 15/150\n",
      "954/956 [============================>.] - ETA: 0s - loss: 0.3093 - accuracy: 0.8775\n",
      "Epoch 00015: val_accuracy improved from 0.87489 to 0.87636, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 4ms/step - loss: 0.3092 - accuracy: 0.8776 - val_loss: 0.3165 - val_accuracy: 0.8764\n",
      "Epoch 16/150\n",
      "953/956 [============================>.] - ETA: 0s - loss: 0.3069 - accuracy: 0.8763\n",
      "Epoch 00016: val_accuracy improved from 0.87636 to 0.88372, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.3068 - accuracy: 0.8763 - val_loss: 0.3014 - val_accuracy: 0.8837\n",
      "Epoch 17/150\n",
      "949/956 [============================>.] - ETA: 0s - loss: 0.2960 - accuracy: 0.8825\n",
      "Epoch 00017: val_accuracy did not improve from 0.88372\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2959 - accuracy: 0.8826 - val_loss: 0.3043 - val_accuracy: 0.8778\n",
      "Epoch 18/150\n",
      "942/956 [============================>.] - ETA: 0s - loss: 0.2871 - accuracy: 0.8863\n",
      "Epoch 00018: val_accuracy did not improve from 0.88372\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2875 - accuracy: 0.8862 - val_loss: 0.3000 - val_accuracy: 0.8781\n",
      "Epoch 19/150\n",
      "940/956 [============================>.] - ETA: 0s - loss: 0.2785 - accuracy: 0.8896\n",
      "Epoch 00019: val_accuracy improved from 0.88372 to 0.88784, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2782 - accuracy: 0.8895 - val_loss: 0.2818 - val_accuracy: 0.8878\n",
      "Epoch 20/150\n",
      "946/956 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.8928\n",
      "Epoch 00020: val_accuracy did not improve from 0.88784\n",
      "956/956 [==============================] - 2s 3ms/step - loss: 0.2722 - accuracy: 0.8927 - val_loss: 0.2791 - val_accuracy: 0.8873\n",
      "Epoch 21/150\n",
      "939/956 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.8973\n",
      "Epoch 00021: val_accuracy did not improve from 0.88784\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2655 - accuracy: 0.8972 - val_loss: 0.2754 - val_accuracy: 0.8873\n",
      "Epoch 22/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.2596 - accuracy: 0.8986\n",
      "Epoch 00022: val_accuracy improved from 0.88784 to 0.90374, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2595 - accuracy: 0.8987 - val_loss: 0.2584 - val_accuracy: 0.9037\n",
      "Epoch 23/150\n",
      "951/956 [============================>.] - ETA: 0s - loss: 0.2540 - accuracy: 0.9001\n",
      "Epoch 00023: val_accuracy improved from 0.90374 to 0.90433, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2547 - accuracy: 0.8999 - val_loss: 0.2591 - val_accuracy: 0.9043\n",
      "Epoch 24/150\n",
      "937/956 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.9053\n",
      "Epoch 00024: val_accuracy did not improve from 0.90433\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2483 - accuracy: 0.9051 - val_loss: 0.2513 - val_accuracy: 0.9034\n",
      "Epoch 25/150\n",
      "946/956 [============================>.] - ETA: 0s - loss: 0.2489 - accuracy: 0.9045\n",
      "Epoch 00025: val_accuracy did not improve from 0.90433\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2483 - accuracy: 0.9048 - val_loss: 0.2589 - val_accuracy: 0.9011\n",
      "Epoch 26/150\n",
      "940/956 [============================>.] - ETA: 0s - loss: 0.2440 - accuracy: 0.9060\n",
      "Epoch 00026: val_accuracy did not improve from 0.90433\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2433 - accuracy: 0.9063 - val_loss: 0.2563 - val_accuracy: 0.9020\n",
      "Epoch 27/150\n",
      "952/956 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.9081\n",
      "Epoch 00027: val_accuracy improved from 0.90433 to 0.90521, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2429 - accuracy: 0.9078 - val_loss: 0.2475 - val_accuracy: 0.9052\n",
      "Epoch 28/150\n",
      "955/956 [============================>.] - ETA: 0s - loss: 0.2322 - accuracy: 0.9112\n",
      "Epoch 00028: val_accuracy did not improve from 0.90521\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2322 - accuracy: 0.9112 - val_loss: 0.2437 - val_accuracy: 0.9049\n",
      "Epoch 29/150\n",
      "946/956 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.9128\n",
      "Epoch 00029: val_accuracy did not improve from 0.90521\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2293 - accuracy: 0.9128 - val_loss: 0.2522 - val_accuracy: 0.9005\n",
      "Epoch 30/150\n",
      "953/956 [============================>.] - ETA: 0s - loss: 0.2268 - accuracy: 0.9148\n",
      "Epoch 00030: val_accuracy improved from 0.90521 to 0.91139, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2265 - accuracy: 0.9149 - val_loss: 0.2423 - val_accuracy: 0.9114\n",
      "Epoch 31/150\n",
      "947/956 [============================>.] - ETA: 0s - loss: 0.2255 - accuracy: 0.9135\n",
      "Epoch 00031: val_accuracy did not improve from 0.91139\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2256 - accuracy: 0.9135 - val_loss: 0.2418 - val_accuracy: 0.9082\n",
      "Epoch 32/150\n",
      "947/956 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9146\n",
      "Epoch 00032: val_accuracy improved from 0.91139 to 0.91581, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 4ms/step - loss: 0.2220 - accuracy: 0.9144 - val_loss: 0.2351 - val_accuracy: 0.9158\n",
      "Epoch 33/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.9180\n",
      "Epoch 00033: val_accuracy did not improve from 0.91581\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2118 - accuracy: 0.9180 - val_loss: 0.2505 - val_accuracy: 0.9067\n",
      "Epoch 34/150\n",
      "953/956 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9169\n",
      "Epoch 00034: val_accuracy did not improve from 0.91581\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2147 - accuracy: 0.9169 - val_loss: 0.2398 - val_accuracy: 0.9108\n",
      "Epoch 35/150\n",
      "945/956 [============================>.] - ETA: 0s - loss: 0.2118 - accuracy: 0.9213\n",
      "Epoch 00035: val_accuracy did not improve from 0.91581\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2118 - accuracy: 0.9211 - val_loss: 0.2381 - val_accuracy: 0.9084\n",
      "Epoch 36/150\n",
      "945/956 [============================>.] - ETA: 0s - loss: 0.2091 - accuracy: 0.9201\n",
      "Epoch 00036: val_accuracy improved from 0.91581 to 0.92022, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2093 - accuracy: 0.9199 - val_loss: 0.2245 - val_accuracy: 0.9202\n",
      "Epoch 37/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.2053 - accuracy: 0.9221\n",
      "Epoch 00037: val_accuracy did not improve from 0.92022\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2052 - accuracy: 0.9221 - val_loss: 0.2301 - val_accuracy: 0.9161\n",
      "Epoch 38/150\n",
      "942/956 [============================>.] - ETA: 0s - loss: 0.1993 - accuracy: 0.9263\n",
      "Epoch 00038: val_accuracy improved from 0.92022 to 0.92317, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1998 - accuracy: 0.9260 - val_loss: 0.2193 - val_accuracy: 0.9232\n",
      "Epoch 39/150\n",
      "948/956 [============================>.] - ETA: 0s - loss: 0.2001 - accuracy: 0.9252\n",
      "Epoch 00039: val_accuracy did not improve from 0.92317\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2003 - accuracy: 0.9250 - val_loss: 0.2242 - val_accuracy: 0.9176\n",
      "Epoch 40/150\n",
      "935/956 [============================>.] - ETA: 0s - loss: 0.1964 - accuracy: 0.9267\n",
      "Epoch 00040: val_accuracy did not improve from 0.92317\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1963 - accuracy: 0.9267 - val_loss: 0.2182 - val_accuracy: 0.9199\n",
      "Epoch 41/150\n",
      "953/956 [============================>.] - ETA: 0s - loss: 0.1993 - accuracy: 0.9238\n",
      "Epoch 00041: val_accuracy did not improve from 0.92317\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.2016 - accuracy: 0.9238 - val_loss: 0.2259 - val_accuracy: 0.9226\n",
      "Epoch 42/150\n",
      "952/956 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9257\n",
      "Epoch 00042: val_accuracy did not improve from 0.92317\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1952 - accuracy: 0.9259 - val_loss: 0.2416 - val_accuracy: 0.9143\n",
      "Epoch 43/150\n",
      "941/956 [============================>.] - ETA: 0s - loss: 0.1904 - accuracy: 0.9296\n",
      "Epoch 00043: val_accuracy did not improve from 0.92317\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1905 - accuracy: 0.9294 - val_loss: 0.2142 - val_accuracy: 0.9223\n",
      "Epoch 44/150\n",
      "953/956 [============================>.] - ETA: 0s - loss: 0.1854 - accuracy: 0.9311\n",
      "Epoch 00044: val_accuracy did not improve from 0.92317\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1854 - accuracy: 0.9311 - val_loss: 0.2206 - val_accuracy: 0.9196\n",
      "Epoch 45/150\n",
      "937/956 [============================>.] - ETA: 0s - loss: 0.1890 - accuracy: 0.9305\n",
      "Epoch 00045: val_accuracy did not improve from 0.92317\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1890 - accuracy: 0.9306 - val_loss: 0.2209 - val_accuracy: 0.9196\n",
      "Epoch 46/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9323\n",
      "Epoch 00046: val_accuracy improved from 0.92317 to 0.92847, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1844 - accuracy: 0.9323 - val_loss: 0.2055 - val_accuracy: 0.9285\n",
      "Epoch 47/150\n",
      "949/956 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9337\n",
      "Epoch 00047: val_accuracy did not improve from 0.92847\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1779 - accuracy: 0.9337 - val_loss: 0.2187 - val_accuracy: 0.9241\n",
      "Epoch 48/150\n",
      "941/956 [============================>.] - ETA: 0s - loss: 0.1799 - accuracy: 0.9328\n",
      "Epoch 00048: val_accuracy did not improve from 0.92847\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1803 - accuracy: 0.9327 - val_loss: 0.2088 - val_accuracy: 0.9276\n",
      "Epoch 49/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9346\n",
      "Epoch 00049: val_accuracy did not improve from 0.92847\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1782 - accuracy: 0.9345 - val_loss: 0.2161 - val_accuracy: 0.9238\n",
      "Epoch 50/150\n",
      "948/956 [============================>.] - ETA: 0s - loss: 0.1760 - accuracy: 0.9349\n",
      "Epoch 00050: val_accuracy did not improve from 0.92847\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1758 - accuracy: 0.9349 - val_loss: 0.2035 - val_accuracy: 0.9270\n",
      "Epoch 51/150\n",
      "940/956 [============================>.] - ETA: 0s - loss: 0.1751 - accuracy: 0.9342\n",
      "Epoch 00051: val_accuracy did not improve from 0.92847\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1748 - accuracy: 0.9343 - val_loss: 0.2084 - val_accuracy: 0.9249\n",
      "Epoch 52/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9370\n",
      "Epoch 00052: val_accuracy improved from 0.92847 to 0.93112, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1701 - accuracy: 0.9369 - val_loss: 0.2058 - val_accuracy: 0.9311\n",
      "Epoch 53/150\n",
      "950/956 [============================>.] - ETA: 0s - loss: 0.1684 - accuracy: 0.9384\n",
      "Epoch 00053: val_accuracy improved from 0.93112 to 0.93170, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1685 - accuracy: 0.9383 - val_loss: 0.1988 - val_accuracy: 0.9317\n",
      "Epoch 54/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9381\n",
      "Epoch 00054: val_accuracy did not improve from 0.93170\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1712 - accuracy: 0.9379 - val_loss: 0.1979 - val_accuracy: 0.9311\n",
      "Epoch 55/150\n",
      "940/956 [============================>.] - ETA: 0s - loss: 0.1658 - accuracy: 0.9379\n",
      "Epoch 00055: val_accuracy did not improve from 0.93170\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1656 - accuracy: 0.9378 - val_loss: 0.2229 - val_accuracy: 0.9246\n",
      "Epoch 56/150\n",
      "953/956 [============================>.] - ETA: 0s - loss: 0.1677 - accuracy: 0.9399\n",
      "Epoch 00056: val_accuracy did not improve from 0.93170\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1678 - accuracy: 0.9398 - val_loss: 0.2096 - val_accuracy: 0.9296\n",
      "Epoch 57/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.1617 - accuracy: 0.9398\n",
      "Epoch 00057: val_accuracy improved from 0.93170 to 0.93406, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1617 - accuracy: 0.9398 - val_loss: 0.2006 - val_accuracy: 0.9341\n",
      "Epoch 58/150\n",
      "942/956 [============================>.] - ETA: 0s - loss: 0.1600 - accuracy: 0.9407\n",
      "Epoch 00058: val_accuracy did not improve from 0.93406\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1602 - accuracy: 0.9405 - val_loss: 0.2087 - val_accuracy: 0.9267\n",
      "Epoch 59/150\n",
      "941/956 [============================>.] - ETA: 0s - loss: 0.1606 - accuracy: 0.9420\n",
      "Epoch 00059: val_accuracy did not improve from 0.93406\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1603 - accuracy: 0.9421 - val_loss: 0.2116 - val_accuracy: 0.9282\n",
      "Epoch 60/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.1579 - accuracy: 0.9410\n",
      "Epoch 00060: val_accuracy did not improve from 0.93406\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1579 - accuracy: 0.9410 - val_loss: 0.2088 - val_accuracy: 0.9288\n",
      "Epoch 61/150\n",
      "951/956 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 0.9431\n",
      "Epoch 00061: val_accuracy did not improve from 0.93406\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1579 - accuracy: 0.9429 - val_loss: 0.2029 - val_accuracy: 0.9341\n",
      "Epoch 62/150\n",
      "949/956 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9431\n",
      "Epoch 00062: val_accuracy did not improve from 0.93406\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1552 - accuracy: 0.9430 - val_loss: 0.2156 - val_accuracy: 0.9296\n",
      "Epoch 63/150\n",
      "954/956 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 0.9440\n",
      "Epoch 00063: val_accuracy did not improve from 0.93406\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1541 - accuracy: 0.9440 - val_loss: 0.2092 - val_accuracy: 0.9302\n",
      "Epoch 64/150\n",
      "950/956 [============================>.] - ETA: 0s - loss: 0.1525 - accuracy: 0.9449\n",
      "Epoch 00064: val_accuracy improved from 0.93406 to 0.93553, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1523 - accuracy: 0.9450 - val_loss: 0.2074 - val_accuracy: 0.9355\n",
      "Epoch 65/150\n",
      "938/956 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9456\n",
      "Epoch 00065: val_accuracy did not improve from 0.93553\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1517 - accuracy: 0.9453 - val_loss: 0.2170 - val_accuracy: 0.9285\n",
      "Epoch 66/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9454\n",
      "Epoch 00066: val_accuracy did not improve from 0.93553\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1511 - accuracy: 0.9453 - val_loss: 0.2031 - val_accuracy: 0.9344\n",
      "Epoch 67/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.1481 - accuracy: 0.9469\n",
      "Epoch 00067: val_accuracy improved from 0.93553 to 0.93700, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1482 - accuracy: 0.9467 - val_loss: 0.1970 - val_accuracy: 0.9370\n",
      "Epoch 68/150\n",
      "946/956 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.9440\n",
      "Epoch 00068: val_accuracy improved from 0.93700 to 0.93906, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1463 - accuracy: 0.9441 - val_loss: 0.1999 - val_accuracy: 0.9391\n",
      "Epoch 69/150\n",
      "946/956 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9484\n",
      "Epoch 00069: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1457 - accuracy: 0.9485 - val_loss: 0.2136 - val_accuracy: 0.9299\n",
      "Epoch 70/150\n",
      "940/956 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 0.9469\n",
      "Epoch 00070: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1453 - accuracy: 0.9466 - val_loss: 0.2174 - val_accuracy: 0.9288\n",
      "Epoch 71/150\n",
      "950/956 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9473\n",
      "Epoch 00071: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1501 - accuracy: 0.9472 - val_loss: 0.1976 - val_accuracy: 0.9332\n",
      "Epoch 72/150\n",
      "949/956 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9469\n",
      "Epoch 00072: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1466 - accuracy: 0.9470 - val_loss: 0.2002 - val_accuracy: 0.9364\n",
      "Epoch 73/150\n",
      "954/956 [============================>.] - ETA: 0s - loss: 0.1434 - accuracy: 0.9477\n",
      "Epoch 00073: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1435 - accuracy: 0.9477 - val_loss: 0.2024 - val_accuracy: 0.9358\n",
      "Epoch 74/150\n",
      "949/956 [============================>.] - ETA: 0s - loss: 0.1432 - accuracy: 0.9474\n",
      "Epoch 00074: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1431 - accuracy: 0.9474 - val_loss: 0.2086 - val_accuracy: 0.9338\n",
      "Epoch 75/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9503\n",
      "Epoch 00075: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1385 - accuracy: 0.9502 - val_loss: 0.1990 - val_accuracy: 0.9323\n",
      "Epoch 76/150\n",
      "952/956 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.9509\n",
      "Epoch 00076: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1366 - accuracy: 0.9507 - val_loss: 0.2169 - val_accuracy: 0.9282\n",
      "Epoch 77/150\n",
      "955/956 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9498\n",
      "Epoch 00077: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1397 - accuracy: 0.9499 - val_loss: 0.2146 - val_accuracy: 0.9320\n",
      "Epoch 78/150\n",
      "948/956 [============================>.] - ETA: 0s - loss: 0.1337 - accuracy: 0.9509\n",
      "Epoch 00078: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1334 - accuracy: 0.9510 - val_loss: 0.2210 - val_accuracy: 0.9288\n",
      "Epoch 79/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9497\n",
      "Epoch 00079: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1382 - accuracy: 0.9497 - val_loss: 0.2026 - val_accuracy: 0.9364\n",
      "Epoch 80/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.1349 - accuracy: 0.9513\n",
      "Epoch 00080: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1351 - accuracy: 0.9511 - val_loss: 0.2063 - val_accuracy: 0.9355\n",
      "Epoch 81/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.9527\n",
      "Epoch 00081: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1316 - accuracy: 0.9530 - val_loss: 0.2079 - val_accuracy: 0.9329\n",
      "Epoch 82/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.9518\n",
      "Epoch 00082: val_accuracy did not improve from 0.93906\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1323 - accuracy: 0.9518 - val_loss: 0.2184 - val_accuracy: 0.9329\n",
      "Epoch 83/150\n",
      "942/956 [============================>.] - ETA: 0s - loss: 0.1334 - accuracy: 0.9517\n",
      "Epoch 00083: val_accuracy improved from 0.93906 to 0.94024, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1337 - accuracy: 0.9517 - val_loss: 0.2034 - val_accuracy: 0.9402\n",
      "Epoch 84/150\n",
      "949/956 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.9548\n",
      "Epoch 00084: val_accuracy did not improve from 0.94024\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1308 - accuracy: 0.9547 - val_loss: 0.2129 - val_accuracy: 0.9344\n",
      "Epoch 85/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9540\n",
      "Epoch 00085: val_accuracy did not improve from 0.94024\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1309 - accuracy: 0.9540 - val_loss: 0.2050 - val_accuracy: 0.9391\n",
      "Epoch 86/150\n",
      "937/956 [============================>.] - ETA: 0s - loss: 0.1314 - accuracy: 0.9528\n",
      "Epoch 00086: val_accuracy did not improve from 0.94024\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1313 - accuracy: 0.9530 - val_loss: 0.2031 - val_accuracy: 0.9382\n",
      "Epoch 87/150\n",
      "937/956 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 0.9541\n",
      "Epoch 00087: val_accuracy did not improve from 0.94024\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1309 - accuracy: 0.9542 - val_loss: 0.2055 - val_accuracy: 0.9344\n",
      "Epoch 88/150\n",
      "942/956 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.9558\n",
      "Epoch 00088: val_accuracy improved from 0.94024 to 0.94083, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1260 - accuracy: 0.9559 - val_loss: 0.2066 - val_accuracy: 0.9408\n",
      "Epoch 89/150\n",
      "953/956 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9558\n",
      "Epoch 00089: val_accuracy did not improve from 0.94083\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1268 - accuracy: 0.9558 - val_loss: 0.2000 - val_accuracy: 0.9391\n",
      "Epoch 90/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.1247 - accuracy: 0.9556\n",
      "Epoch 00090: val_accuracy improved from 0.94083 to 0.94171, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 4ms/step - loss: 0.1249 - accuracy: 0.9554 - val_loss: 0.1900 - val_accuracy: 0.9417\n",
      "Epoch 91/150\n",
      "948/956 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9555\n",
      "Epoch 00091: val_accuracy did not improve from 0.94171\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1283 - accuracy: 0.9556 - val_loss: 0.2014 - val_accuracy: 0.9402\n",
      "Epoch 92/150\n",
      "942/956 [============================>.] - ETA: 0s - loss: 0.1259 - accuracy: 0.9559\n",
      "Epoch 00092: val_accuracy did not improve from 0.94171\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1258 - accuracy: 0.9560 - val_loss: 0.2161 - val_accuracy: 0.9364\n",
      "Epoch 93/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9566\n",
      "Epoch 00093: val_accuracy did not improve from 0.94171\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1236 - accuracy: 0.9566 - val_loss: 0.1974 - val_accuracy: 0.9394\n",
      "Epoch 94/150\n",
      "936/956 [============================>.] - ETA: 0s - loss: 0.1212 - accuracy: 0.9581\n",
      "Epoch 00094: val_accuracy did not improve from 0.94171\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1213 - accuracy: 0.9580 - val_loss: 0.2016 - val_accuracy: 0.9376\n",
      "Epoch 95/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9567\n",
      "Epoch 00095: val_accuracy did not improve from 0.94171\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1226 - accuracy: 0.9564 - val_loss: 0.2023 - val_accuracy: 0.9399\n",
      "Epoch 96/150\n",
      "942/956 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.9575\n",
      "Epoch 00096: val_accuracy did not improve from 0.94171\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1207 - accuracy: 0.9572 - val_loss: 0.1899 - val_accuracy: 0.9399\n",
      "Epoch 97/150\n",
      "955/956 [============================>.] - ETA: 0s - loss: 0.1218 - accuracy: 0.9574\n",
      "Epoch 00097: val_accuracy did not improve from 0.94171\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1218 - accuracy: 0.9574 - val_loss: 0.2057 - val_accuracy: 0.9382\n",
      "Epoch 98/150\n",
      "940/956 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9599\n",
      "Epoch 00098: val_accuracy did not improve from 0.94171\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1163 - accuracy: 0.9598 - val_loss: 0.1976 - val_accuracy: 0.9414\n",
      "Epoch 99/150\n",
      "949/956 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9572\n",
      "Epoch 00099: val_accuracy did not improve from 0.94171\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1204 - accuracy: 0.9572 - val_loss: 0.1934 - val_accuracy: 0.9411\n",
      "Epoch 100/150\n",
      "942/956 [============================>.] - ETA: 0s - loss: 0.1198 - accuracy: 0.9587\n",
      "Epoch 00100: val_accuracy did not improve from 0.94171\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1195 - accuracy: 0.9588 - val_loss: 0.2321 - val_accuracy: 0.9364\n",
      "Epoch 101/150\n",
      "938/956 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9574\n",
      "Epoch 00101: val_accuracy improved from 0.94171 to 0.94201, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1212 - accuracy: 0.9576 - val_loss: 0.1988 - val_accuracy: 0.9420\n",
      "Epoch 102/150\n",
      "946/956 [============================>.] - ETA: 0s - loss: 0.1175 - accuracy: 0.9592\n",
      "Epoch 00102: val_accuracy did not improve from 0.94201\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1174 - accuracy: 0.9591 - val_loss: 0.2012 - val_accuracy: 0.9370\n",
      "Epoch 103/150\n",
      "948/956 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9606\n",
      "Epoch 00103: val_accuracy did not improve from 0.94201\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1155 - accuracy: 0.9607 - val_loss: 0.1977 - val_accuracy: 0.9420\n",
      "Epoch 104/150\n",
      "951/956 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9600\n",
      "Epoch 00104: val_accuracy did not improve from 0.94201\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1165 - accuracy: 0.9601 - val_loss: 0.1969 - val_accuracy: 0.9391\n",
      "Epoch 105/150\n",
      "948/956 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 0.9606\n",
      "Epoch 00105: val_accuracy improved from 0.94201 to 0.94319, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1165 - accuracy: 0.9607 - val_loss: 0.1956 - val_accuracy: 0.9432\n",
      "Epoch 106/150\n",
      "948/956 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.9613\n",
      "Epoch 00106: val_accuracy did not improve from 0.94319\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1132 - accuracy: 0.9612 - val_loss: 0.2003 - val_accuracy: 0.9408\n",
      "Epoch 107/150\n",
      "950/956 [============================>.] - ETA: 0s - loss: 0.1149 - accuracy: 0.9596\n",
      "Epoch 00107: val_accuracy did not improve from 0.94319\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1153 - accuracy: 0.9594 - val_loss: 0.2050 - val_accuracy: 0.9429\n",
      "Epoch 108/150\n",
      "946/956 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9606\n",
      "Epoch 00108: val_accuracy improved from 0.94319 to 0.94613, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1167 - accuracy: 0.9606 - val_loss: 0.1885 - val_accuracy: 0.9461\n",
      "Epoch 109/150\n",
      "939/956 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 0.9605\n",
      "Epoch 00109: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1132 - accuracy: 0.9605 - val_loss: 0.2103 - val_accuracy: 0.9379\n",
      "Epoch 110/150\n",
      "947/956 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.9611\n",
      "Epoch 00110: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1122 - accuracy: 0.9612 - val_loss: 0.1983 - val_accuracy: 0.9435\n",
      "Epoch 111/150\n",
      "938/956 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 0.9611\n",
      "Epoch 00111: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1120 - accuracy: 0.9612 - val_loss: 0.2115 - val_accuracy: 0.9414\n",
      "Epoch 112/150\n",
      "953/956 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9607\n",
      "Epoch 00112: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1127 - accuracy: 0.9607 - val_loss: 0.2052 - val_accuracy: 0.9408\n",
      "Epoch 113/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.9625\n",
      "Epoch 00113: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.9625 - val_loss: 0.1938 - val_accuracy: 0.9420\n",
      "Epoch 114/150\n",
      "955/956 [============================>.] - ETA: 0s - loss: 0.1105 - accuracy: 0.9618\n",
      "Epoch 00114: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1104 - accuracy: 0.9619 - val_loss: 0.2086 - val_accuracy: 0.9408\n",
      "Epoch 115/150\n",
      "940/956 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.9619\n",
      "Epoch 00115: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1086 - accuracy: 0.9621 - val_loss: 0.2150 - val_accuracy: 0.9388\n",
      "Epoch 116/150\n",
      "950/956 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9618\n",
      "Epoch 00116: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1102 - accuracy: 0.9618 - val_loss: 0.2032 - val_accuracy: 0.9441\n",
      "Epoch 117/150\n",
      "945/956 [============================>.] - ETA: 0s - loss: 0.1080 - accuracy: 0.9634\n",
      "Epoch 00117: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1079 - accuracy: 0.9634 - val_loss: 0.2028 - val_accuracy: 0.9420\n",
      "Epoch 118/150\n",
      "951/956 [============================>.] - ETA: 0s - loss: 0.1071 - accuracy: 0.9628\n",
      "Epoch 00118: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1071 - accuracy: 0.9629 - val_loss: 0.2049 - val_accuracy: 0.9429\n",
      "Epoch 119/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9626\n",
      "Epoch 00119: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1103 - accuracy: 0.9626 - val_loss: 0.2007 - val_accuracy: 0.9432\n",
      "Epoch 120/150\n",
      "955/956 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.9647\n",
      "Epoch 00120: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1048 - accuracy: 0.9646 - val_loss: 0.2037 - val_accuracy: 0.9426\n",
      "Epoch 121/150\n",
      "954/956 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 0.9653\n",
      "Epoch 00121: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1039 - accuracy: 0.9653 - val_loss: 0.2069 - val_accuracy: 0.9399\n",
      "Epoch 122/150\n",
      "945/956 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.9641\n",
      "Epoch 00122: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1068 - accuracy: 0.9640 - val_loss: 0.1954 - val_accuracy: 0.9411\n",
      "Epoch 123/150\n",
      "942/956 [============================>.] - ETA: 0s - loss: 0.1097 - accuracy: 0.9623\n",
      "Epoch 00123: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1094 - accuracy: 0.9624 - val_loss: 0.1979 - val_accuracy: 0.9450\n",
      "Epoch 124/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9644\n",
      "Epoch 00124: val_accuracy did not improve from 0.94613\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1039 - accuracy: 0.9644 - val_loss: 0.1944 - val_accuracy: 0.9447\n",
      "Epoch 125/150\n",
      "954/956 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.9657\n",
      "Epoch 00125: val_accuracy improved from 0.94613 to 0.94819, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 4ms/step - loss: 0.1028 - accuracy: 0.9657 - val_loss: 0.1860 - val_accuracy: 0.9482\n",
      "Epoch 126/150\n",
      "951/956 [============================>.] - ETA: 0s - loss: 0.1040 - accuracy: 0.9644\n",
      "Epoch 00126: val_accuracy did not improve from 0.94819\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1042 - accuracy: 0.9643 - val_loss: 0.1955 - val_accuracy: 0.9455\n",
      "Epoch 127/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9640\n",
      "Epoch 00127: val_accuracy did not improve from 0.94819\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1065 - accuracy: 0.9639 - val_loss: 0.1961 - val_accuracy: 0.9450\n",
      "Epoch 128/150\n",
      "947/956 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.9665\n",
      "Epoch 00128: val_accuracy did not improve from 0.94819\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1014 - accuracy: 0.9665 - val_loss: 0.1913 - val_accuracy: 0.9470\n",
      "Epoch 129/150\n",
      "951/956 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 0.9653\n",
      "Epoch 00129: val_accuracy did not improve from 0.94819\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1035 - accuracy: 0.9653 - val_loss: 0.1936 - val_accuracy: 0.9438\n",
      "Epoch 130/150\n",
      "955/956 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.9657\n",
      "Epoch 00130: val_accuracy did not improve from 0.94819\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1029 - accuracy: 0.9657 - val_loss: 0.2188 - val_accuracy: 0.9373\n",
      "Epoch 131/150\n",
      "945/956 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9664\n",
      "Epoch 00131: val_accuracy did not improve from 0.94819\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1011 - accuracy: 0.9664 - val_loss: 0.2038 - val_accuracy: 0.9391\n",
      "Epoch 132/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9645\n",
      "Epoch 00132: val_accuracy did not improve from 0.94819\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1045 - accuracy: 0.9645 - val_loss: 0.2059 - val_accuracy: 0.9388\n",
      "Epoch 133/150\n",
      "938/956 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9669\n",
      "Epoch 00133: val_accuracy did not improve from 0.94819\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1011 - accuracy: 0.9669 - val_loss: 0.2031 - val_accuracy: 0.9438\n",
      "Epoch 134/150\n",
      "949/956 [============================>.] - ETA: 0s - loss: 0.1016 - accuracy: 0.9665\n",
      "Epoch 00134: val_accuracy improved from 0.94819 to 0.94937, saving model to /content/drive/My Drive/Financial Analytics/wts/cp.ckpt\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Financial Analytics/wts/cp.ckpt/assets\n",
      "956/956 [==============================] - 3s 4ms/step - loss: 0.1017 - accuracy: 0.9665 - val_loss: 0.1838 - val_accuracy: 0.9494\n",
      "Epoch 135/150\n",
      "941/956 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 0.9673\n",
      "Epoch 00135: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0982 - accuracy: 0.9673 - val_loss: 0.1978 - val_accuracy: 0.9444\n",
      "Epoch 136/150\n",
      "956/956 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9669\n",
      "Epoch 00136: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.1005 - accuracy: 0.9669 - val_loss: 0.1968 - val_accuracy: 0.9429\n",
      "Epoch 137/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.9665\n",
      "Epoch 00137: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0978 - accuracy: 0.9666 - val_loss: 0.1910 - val_accuracy: 0.9458\n",
      "Epoch 138/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.0958 - accuracy: 0.9683\n",
      "Epoch 00138: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0959 - accuracy: 0.9683 - val_loss: 0.2002 - val_accuracy: 0.9423\n",
      "Epoch 139/150\n",
      "944/956 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9676\n",
      "Epoch 00139: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0966 - accuracy: 0.9676 - val_loss: 0.1943 - val_accuracy: 0.9470\n",
      "Epoch 140/150\n",
      "950/956 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9671\n",
      "Epoch 00140: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0984 - accuracy: 0.9672 - val_loss: 0.1958 - val_accuracy: 0.9444\n",
      "Epoch 141/150\n",
      "949/956 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.9670\n",
      "Epoch 00141: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0980 - accuracy: 0.9670 - val_loss: 0.1858 - val_accuracy: 0.9470\n",
      "Epoch 142/150\n",
      "949/956 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9674\n",
      "Epoch 00142: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0992 - accuracy: 0.9675 - val_loss: 0.1927 - val_accuracy: 0.9482\n",
      "Epoch 143/150\n",
      "948/956 [============================>.] - ETA: 0s - loss: 0.0969 - accuracy: 0.9676\n",
      "Epoch 00143: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0974 - accuracy: 0.9674 - val_loss: 0.1907 - val_accuracy: 0.9461\n",
      "Epoch 144/150\n",
      "951/956 [============================>.] - ETA: 0s - loss: 0.0940 - accuracy: 0.9682\n",
      "Epoch 00144: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0941 - accuracy: 0.9681 - val_loss: 0.1919 - val_accuracy: 0.9479\n",
      "Epoch 145/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9691\n",
      "Epoch 00145: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0935 - accuracy: 0.9689 - val_loss: 0.2018 - val_accuracy: 0.9485\n",
      "Epoch 146/150\n",
      "945/956 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9686\n",
      "Epoch 00146: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0945 - accuracy: 0.9685 - val_loss: 0.1969 - val_accuracy: 0.9476\n",
      "Epoch 147/150\n",
      "951/956 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 0.9691\n",
      "Epoch 00147: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0934 - accuracy: 0.9692 - val_loss: 0.2102 - val_accuracy: 0.9441\n",
      "Epoch 148/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9682\n",
      "Epoch 00148: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0964 - accuracy: 0.9683 - val_loss: 0.1993 - val_accuracy: 0.9476\n",
      "Epoch 149/150\n",
      "945/956 [============================>.] - ETA: 0s - loss: 0.0952 - accuracy: 0.9680\n",
      "Epoch 00149: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0951 - accuracy: 0.9680 - val_loss: 0.1963 - val_accuracy: 0.9464\n",
      "Epoch 150/150\n",
      "943/956 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9687\n",
      "Epoch 00150: val_accuracy did not improve from 0.94937\n",
      "956/956 [==============================] - 3s 3ms/step - loss: 0.0938 - accuracy: 0.9688 - val_loss: 0.1914 - val_accuracy: 0.9491\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit(X,y,epochs=100,batch_size=32) -> 99.45\n",
    "history = model.fit(X_train, y_train, validation_split = 0.1, validation_data = (X_test, y_test), epochs = 150, batch_size = 32, callbacks = [lrs, checkpoint])\n",
    "#validation_data=(X_test,y_test)\n",
    "#,callbacks=[lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rOmAiyN9qjcs",
    "outputId": "52003e19-067b-4e05-ab07-f84c3d030dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.70\n"
     ]
    }
   ],
   "source": [
    "i, accuracy = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Accuracy: %.2f' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "5hFGb9-L4BgI",
    "outputId": "fc0a5cf7-24e3-488c-c318-edb6f44d381e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_accuracy'], label = 'validation')\n",
    "#plt.plot(hist.history['loss'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "Hc5oCcSJ4Wyf",
    "outputId": "9f4923ff-2391-4aa5-9887-30c0713b7e8c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = \"training\")\n",
    "#plt.plot(hist.history['loss'])\n",
    "#plt.show()\n",
    "\n",
    "plt.plot(history.history['val_loss'], label = 'validation')\n",
    "#plt.plot(hist.history['loss'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdiydX5R4fwP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "financial analytics.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
